[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Timbila NIKIEMA",
    "section": "",
    "text": "Timbila NIKIEMA\n\nHello and welcome to my page!\nMy name is Timbila Nikiema, and I have built a solid educational foundation in finance, complemented by a growing expertise in quantitative analysis. I earned my Bachelor of Business Administration with a major in Finance from Baruch College’s Zicklin School of Business, where I developed a strong analytical mindset and a passion for financial modeling.\nCurrently, I am furthering my education by pursuing a Master of Science in Quantitative Methods and Modeling at Baruch College. This advanced degree is enhancing my ability to apply complex quantitative techniques to real-world financial challenges.\nIn my professional roles as a Senior Financial Analyst at St. Barnabas Health System and a Senior Corporate Financial Analyst at Northwell Health, I have gained valuable experience in financial analysis, budget management, and strategic planning. These experiences have solidified my commitment to using data-driven insights to support organizational success."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Timbila NIKIEMA",
    "section": "",
    "text": "BARUCH COLLEGE | ZICKLIN SCHOOL OF BUSINESS\nMaster of Science – MS Quantitative Methods and Modeling\nJune 2025\nBachelor of Business Administration\nDecember 2018\nMajor: Finance, Minor: Economics"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Timbila NIKIEMA",
    "section": "",
    "text": "ST BARNABAS HEALTH SYSTEM\nSenior Financial Analyst\nOctober 2022 – Present\n\nPrepare monthly grant vouchers and annual budgets to external entities and monitor grant cash payments.\nAssist with monthly account analysis and the preparation of the monthly financial statement process.\nCollaborate with team members to develop the organization’s overall budget.\nReview budget proposals for completeness, accuracy, and compliance with organizational standards.\nMaintain controls over expenditures to ensure adherence to the budget.\nConduct cost-benefit analyses to assess the efficiency and effectiveness of various programs.\nAssist in year-end audit procedures; prepare work papers, inquiries, and other supporting documentation.\nCreate a consolidated budget for the entire organization, integrating various departmental budgets.\nPerform ongoing budget tool updates and adjustments as needed throughout the budgetary cycle.\nAnalyze budget and financial data to develop annual and multi-year budget estimates.\nMonitor the execution of an approved operating budget to ensure funds are properly allocated and spent timely.\nEstimate salaries and expenses based on past data and forecasts of changing costs and requirements.\nDevelop and justify an operating budget.\nMonitor expenditure of budgeted funds and compare them to expected expenditure levels.\nAnalyze trends in fund usage and recommend adjustments in program spending.\nParticipate in the development and analysis of annual and program budget submissions.\n\nNORTHWELL HEALTH\nSenior Corporate Financial Analyst\nOctober 2019 – October 2022\n\nAnalyze past results, perform variance analysis, identify trends, and make recommendations for improvements.\nMaintain proprietary databases including data integrity, timeliness of data input, and accuracy.\nDesign, develop, and modify systems and procedures to enhance departmental processing as needed.\nReport results on a monthly, quarterly, and/or annual basis.\nIncrease productivity by developing automated reporting/forecasting tools.\nRecommend actions by analyzing and interpreting data and making comparative analyses.\nIdentify and drive process improvements, including the creation of standard and ad-hoc reports.\nDevelop and support dynamic Excel-based reporting tools to enhance the reporting process.\nProvide management with ad hoc financial analysis upon request."
  },
  {
    "objectID": "index.html#skills",
    "href": "index.html#skills",
    "title": "Timbila NIKIEMA",
    "section": "",
    "text": "Bloomberg Market Concept\nLanguage: Advanced French\nComputers: Microsoft Excel, Microsoft Access, PowerPoint, Tableau, StrataJazz, Oracle Cloud, SQL Fundamentals"
  },
  {
    "objectID": "mp02.html#data-handling-and-processing",
    "href": "mp02.html#data-handling-and-processing",
    "title": "Mini-Project #02: The Business of Show Business",
    "section": "",
    "text": "IMDb provides extensive data, which required careful sub-sampling and filtering to make it manageable. To achieve this, we will take the following steps:\nStep 1: Download the data from IMDb and create the following tables:\n\nNAME_BASICS: contains information about people (actors, directors, writers, etc.) in the IMDb database.\nTITLE_BASICS: contains basic information about movies, TV shows, and other titles listed in IMDb.\nTITLE_EPISODES: contains information specific to individual TV episodes.\nTITLE_RATINGS: contains IMDb ratings for titles.\nTITLE_CREW: contains information about the director(s) and writer(s) for each title.\nTITLE_PRINCIPALS: contains information about the key cast and crew involved in a title.\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(stringr)\nlibrary(grid)\nlibrary(shadowtext)\nlibrary(ggplot2)\nlibrary(gganimate)\nlibrary(plotly)\nlibrary(treemap)\nlibrary(gifski)\nlibrary(DT)\n\nget_imdb_file &lt;- function(fname){\n    BASE_URL &lt;- \"https://datasets.imdbws.com/\"\n    fname_ext &lt;- paste0(fname, \".tsv.gz\")\n    if(!file.exists(fname_ext)){\n        FILE_URL &lt;- paste0(BASE_URL, fname_ext)\n        download.file(FILE_URL, \n                      destfile = fname_ext)\n    }\n    as.data.frame(readr::read_tsv(fname_ext, lazy=FALSE))\n}\n\nNAME_BASICS      &lt;- get_imdb_file(\"name.basics\")\nTITLE_BASICS     &lt;- get_imdb_file(\"title.basics\")\nTITLE_EPISODES   &lt;- get_imdb_file(\"title.episode\")\nTITLE_RATINGS    &lt;- get_imdb_file(\"title.ratings\")\nTITLE_CREW       &lt;- get_imdb_file(\"title.crew\")\nTITLE_PRINCIPALS &lt;- get_imdb_file(\"title.principals\")\n\n\nStep 2: Let’s throw out any title with less than 100 ratings. It’s not too hard to see that this drops about 75% of the entire data set.\n\n\nCode\nTITLE_RATINGS |&gt;\n    pull(numVotes) |&gt;\n    quantile()\n\n\n     0%     25%     50%     75%    100% \n      5      11      26     100 2953606 \n\n\nStep 3: Filtering People: The NAME_BASICS table was filtered to include only those with at least two known for credits.\n\n\nCode\nNAME_BASICS &lt;- NAME_BASICS |&gt; \n    filter(str_count(knownForTitles, \",\") &gt; 1)\n\n\nStep 3: Title Filtering: Titles with fewer than 100 IMDb ratings will be removed, retaining only more widely recognized movies.\n\n\nCode\n# Let's drop movie titles with less than 100 votes\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n    filter(numVotes &gt;= 100)\n\n\nStep 4: Joining Tables: A semi-join on the filtered TITLE_RATINGS table will be used to filter the TITLE_BASICS, TITLE_CREW, TITLE_EPISODES, and TITLE_PRINCIPALS tables.\n\n\nCode\nTITLE_BASICS &lt;- TITLE_BASICS |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\n\nTITLE_CREW &lt;- TITLE_CREW |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\n\nTITLE_EPISODES_1 &lt;- TITLE_EPISODES |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\nTITLE_EPISODES_2 &lt;- TITLE_EPISODES |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(parentTconst == tconst))\n\nTITLE_EPISODES &lt;- bind_rows(TITLE_EPISODES_1,\n                            TITLE_EPISODES_2) |&gt;\n    distinct()\n\nTITLE_PRINCIPALS &lt;- TITLE_PRINCIPALS |&gt;\n    semi_join(TITLE_RATINGS, join_by(tconst == tconst))\n\n\nrm(TITLE_EPISODES_1)\nrm(TITLE_EPISODES_2)\n\n\nStep 5: Using a combination of mutate and the coercion functions as.numeric and as.logical to correct the data type for all the tables.\n\n\nCode\n# Correct the column types for NAME_BASICS\nNAME_BASICS &lt;- NAME_BASICS |&gt;\n    mutate(birthYear = as.numeric(birthYear), # Numeric\n           deathYear = as.numeric(deathYear)) # Numeric\n\n# Correct the column types for TITLE_BASICS\nTITLE_BASICS &lt;- TITLE_BASICS |&gt;\n    mutate(\n        tconst = as.character(tconst),  # ID should remain as character\n        titleType = as.character(titleType),  # Character\n        primaryTitle = as.character(primaryTitle),  # Character\n        originalTitle = as.character(originalTitle),  # Character\n        isAdult = as.logical(isAdult),  # Boolean\n        startYear = as.numeric(startYear),  # Numeric\n        endYear = as.numeric(endYear),  # Numeric\n        runtimeMinutes = as.numeric(runtimeMinutes),  # Numeric\n        genres = as.character(genres)  # Character\n    )\n\n# Correct the column types for TITLE_RATINGS\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n    mutate(\n        tconst = as.character(tconst),  # ID should remain as character\n        averageRating = as.numeric(averageRating),  # Numeric\n        numVotes = as.numeric(numVotes)  # Numeric\n    )\n\n# Correct the column types for TITLE_CREW\nTITLE_CREW &lt;- TITLE_CREW |&gt;\n    mutate(\n        tconst = as.character(tconst),  # ID should remain as character\n        directors = as.character(directors),  # Character\n        writers = as.character(writers)  # Character\n    )\n\n# Correct the column types for TITLE_EPISODES\nTITLE_EPISODES &lt;- TITLE_EPISODES |&gt;\n    mutate(\n        tconst = as.character(tconst),  # ID should remain as character\n        parentTconst = as.character(parentTconst),  # Character\n        seasonNumber = as.numeric(seasonNumber),  # Numeric\n        episodeNumber = as.numeric(episodeNumber)  # Numeric\n    )\n\n# Correct the column types for TITLE_PRINCIPALS\nTITLE_PRINCIPALS &lt;- TITLE_PRINCIPALS |&gt;\n    mutate(\n        tconst = as.character(tconst),  # ID should remain as character\n        ordering = as.numeric(ordering),  # Numeric\n        nconst = as.character(nconst),  # Character\n        category = as.character(category),  # Character\n        job = as.character(job),  # Character\n        characters = as.character(characters)  # Character\n    )\n\n\nStep 6: Separating fields with combined multiple values.\n\nglimpse(NAME_BASICS)\n\nRows: 3,190,744\nColumns: 6\n$ nconst            &lt;chr&gt; \"nm0000001\", \"nm0000002\", \"nm0000003\", \"nm0000004\", …\n$ primaryName       &lt;chr&gt; \"Fred Astaire\", \"Lauren Bacall\", \"Brigitte Bardot\", …\n$ birthYear         &lt;dbl&gt; 1899, 1924, 1934, 1949, 1918, 1915, 1899, 1924, 1925…\n$ deathYear         &lt;dbl&gt; 1987, 2014, NA, 1982, 2007, 1982, 1957, 2004, 1984, …\n$ primaryProfession &lt;chr&gt; \"actor,miscellaneous,producer\", \"actress,soundtrack,…\n$ knownForTitles    &lt;chr&gt; \"tt0050419,tt0072308,tt0053137,tt0027125\", \"tt003738…\n\n\nWe can see that in the NAME_BASICS table, both the primaryProfession and knownForTitles columns have combine multiple values. To answer some of the questions, we will need use separate_longer_delim to split the values.\n\n\nCode\nNAME_BASICS |&gt; \n    separate_longer_delim(knownForTitles, \",\") |&gt; \n    separate_longer_delim(primaryProfession, \",\") |&gt; \n    slice_head(n = 10)\n\n\nNow that we have successfully processed the dataset by significantly reducing its size, it is now more manageable for the subsequent analysis."
  },
  {
    "objectID": "mp02.html#initial-exploration",
    "href": "mp02.html#initial-exploration",
    "title": "Mini-Project #02: The Business of Show Business",
    "section": "",
    "text": "How many movies are in our data set? How many TV series? How many TV episodes?\n\n\n\nCode\nTITLE_SUMMARY &lt;- TITLE_BASICS |&gt;\n    filter( titleType %in% c(\"movie\", \"tvSeries\", \"tvEpisode\")) |&gt;\n    group_by(titleType) |&gt;\n    summarize(count = n())|&gt;\n    arrange(desc(count))\n\ndatatable(setNames(TITLE_SUMMARY, c(\"Type\", \"Total\")),\n          options = list(pageLength = 10, autoWidth = TRUE),\n          caption = \"Table 1: Number of Movies, TV series, and TV episodes\")\n\n\nUsing filters applied on the TITLE_BASICS table, we found:\n\nMovies: 132,335\nTV Series: 30,025\nTV Episodes: 156,904\n\n\nWho is the oldest living person in our data set?\n\n\n\nCode\npeople_after_1917_alive &lt;- NAME_BASICS |&gt;\n    filter(birthYear &gt; 1917, is.na(deathYear)) |&gt; # Filter for birthYear &gt; 1917 and deathYear is NA\n    arrange(birthYear) |&gt;\n    slice_head(n = 1)\n\nprint(people_after_1917_alive)\n\n\nThe oldest living person, based on the NAME_BASICS table, is Orest Alikin, born in 1918.\n\nThere is one TV Episode in this data set with a perfect 10/10 rating and 200,000 IMDb ratings. What is it? What series does it belong to?\n\nLet us find the TV Episode with the perfect rating and 200,000 IMDb ratings.First, we need the information from the TITLE_RATINGS and TITLE_BASICS. Then, we will find the TV episode with 10/10 rating and more 200,000 votes.\n\n\nCode\nperfect_episode &lt;- TITLE_RATINGS |&gt;\n    filter(averageRating == 10, numVotes &gt;= 200000) |&gt;\n    inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n    filter(titleType == \"tvEpisode\") |&gt;\n    select(tconst, primaryTitle, titleType, genres, startYear, averageRating, numVotes)\n\nperfect_episode\n\n\nThe TV episode is Ozymandias from Breaking Bad (Season 5, Episode 14), with over 200,000 votes and a perfect score.\n\nWhat four projects is the actor Mark Hammill most known for?\n\n\n\nCode\n# Find Mark Hamill in the NAME_BASICS table\nmark_hamill_titles &lt;- NAME_BASICS |&gt;\n    filter(primaryName == \"Mark Hamill\") |&gt;\n    select(knownForTitles) |&gt;\n    separate_rows(knownForTitles, sep = \",\") # Split the knownForTitles into individual rows\n\n# Join with TITLE_BASICS to get the details of the titles\nmark_hamill_projects &lt;- mark_hamill_titles |&gt;\n    inner_join(TITLE_BASICS, by = c(\"knownForTitles\" = \"tconst\")) |&gt;\n    select(primaryTitle, titleType, startYear)\n\n# View the result\nmark_hamill_projects\n\n\nMark Hamill is most known for:\n\nStar Wars: Episode IV - A New Hope (1977)\nStar Wars: Episode VIII - The Last Jedi (2017)\nStar Wars: Episode V - The Empire Strikes Back (1980)\nStar Wars: Episode VI - Return of the Jedi (1983)\n\n\nWhat TV series, with more than 12 episodes, has the highest average rating?\n\n\n\nCode\n# Step 1: Filter the TITLE_BASICS table to get only TV series and episodes\ntv_series &lt;- TITLE_BASICS |&gt;\n    filter(titleType == \"tvSeries\")\n\ntv_episodes &lt;- TITLE_BASICS |&gt;\n    filter(titleType == \"tvEpisode\")\n\n# Step 2: Join the episodes with their parent TV series using TITLE_EPISODES\ntv_series_episodes &lt;- TITLE_EPISODES |&gt;\n    inner_join(tv_episodes, by = c(\"tconst\" = \"tconst\")) |&gt;\n    inner_join(tv_series, by = c(\"parentTconst\" = \"tconst\"))\n\n# Step 3: Join with the TITLE_RATINGS to get the ratings for the episodes\nepisode_ratings &lt;- tv_series_episodes |&gt;\n    inner_join(TITLE_RATINGS, by = c(\"tconst\" = \"tconst\"))\n\n# Step 4: Calculate the number of episodes and average rating for each TV series\nseries_ratings &lt;- episode_ratings |&gt;\n    group_by(parentTconst) |&gt;\n    summarize(numEpisodes = n(), avgRating = mean(averageRating, na.rm = TRUE)) |&gt;\n    filter(numEpisodes &gt; 12) |&gt;\n    arrange(desc(avgRating))\n\n# Step 5: Join with TITLE_BASICS to get the series name\nbest_tv_series &lt;- series_ratings |&gt;\n    inner_join(tv_series, by = c(\"parentTconst\" = \"tconst\")) |&gt;\n    select(primaryTitle, numEpisodes, startYear, endYear, avgRating) |&gt;\n    slice(1)\n\n# View the result\nbest_tv_series\n\n\nKavya - Ek Jazbaa, Ek Junoon (2023-NA) holds the highest average IMDb rating (9.75) among series with 113 episodes.\n\nIs it true that episodes from later seasons of Happy Days have lower average ratings than the early seasons?\n\n\n\nCode\n# Step 1: Identify the \"Happy Days\" series in TITLE_BASICS\nhappy_days_series &lt;- TITLE_BASICS |&gt;\n    filter(primaryTitle == \"Happy Days\", startYear == 1974) |&gt;\n    select(tconst, primaryTitle, startYear)\n\n# Step 2: Get all episodes of \"Happy Days\" using TITLE_EPISODES\nhappy_days_episodes &lt;- TITLE_EPISODES |&gt;\n    filter(parentTconst == happy_days_series$tconst) |&gt;\n    inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n    select(tconst, seasonNumber, primaryTitle, episodeNumber)\n\n# Step 3: Get ratings for each episode\nhappy_days_ratings &lt;- happy_days_episodes |&gt;\n    inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n    filter(!is.na(seasonNumber))  # Filter out episodes with missing season information\n\n# Step 4: Calculate the average rating for each season\nseason_ratings &lt;- happy_days_ratings |&gt;\n    group_by(seasonNumber) |&gt;\n    summarize(avgRating = mean(averageRating, na.rm = TRUE), numEpisodes = n()) |&gt;\n    arrange(seasonNumber)\n\n# Step 5: Compare the average ratings of early and later seasons\n# We'll split into early (e.g., seasons 1-4) and later (e.g., seasons 5+)\nearly_seasons &lt;- season_ratings |&gt;\n    filter(seasonNumber &lt;= 4) |&gt;\n    summarize(early_avg = mean(avgRating, na.rm = TRUE))\n\nlater_seasons &lt;- season_ratings |&gt;\n    filter(seasonNumber &gt;= 5) |&gt;\n    summarize(later_avg = mean(avgRating, na.rm = TRUE))\n\n# Combine both results into one data frame\ncombined_ratings &lt;- bind_cols(early_seasons, later_seasons)\n\nprint(combined_ratings)\n\n\nOur analysis confirms that the average ratings of episodes in later seasons (6.58) are lower than those of the earlier seasons (7.60)."
  },
  {
    "objectID": "mp02.html#qualifying-success",
    "href": "mp02.html#qualifying-success",
    "title": "Mini-Project #02: The Business of Show Business",
    "section": "",
    "text": "In order to draft a successful proposal for a new movie, we need a success metric that effectively evaluates both the quality (as reflected by average ratings) and popularity (as measured by the number of votes) of a film, ensuring that our decision is data-driven and aimed at maximizing audience appeal and potential profitability.\n\n\nCode\n# Success Metric\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n    mutate(SuccessScore = (averageRating * log(numVotes)) / 10) |&gt;\n    arrange(desc(SuccessScore)) |&gt;\n    inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n    select(tconst, primaryTitle, titleType, numVotes, averageRating, SuccessScore)\n\nhead(TITLE_RATINGS)\n\n\n\nChoose the top 5-10 movies on your metric and confirm that they were indeed box office successes.\n\n\n\nCode\n# Join TITLE_RATINGS with TITLE_BASICS, filter for movies, and select top 10 based on SuccessScore\ntop_movies &lt;- TITLE_RATINGS |&gt;\n    arrange(desc(SuccessScore)) |&gt;\n    select(tconst, averageRating, numVotes, SuccessScore) |&gt;\n    inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n    filter(titleType == \"movie\") |&gt;\n    select(tconst, primaryTitle, titleType, SuccessScore) |&gt;\n    head(10)\n\n# View top movies\nprint(top_movies)\n\n\nThe top movies based on this metric includes The Shawshank Redemptiom, The Dark Knight, and The Godfather - all recognized as major box office hits.\n\nChoose 3-5 movies with large numbers of IMDb votes that score poorly on your success metric and confirm that they are indeed of low quality.\n\n\n\nCode\n# Define a threshold for low success score\nthreshold &lt;- quantile(TITLE_RATINGS$SuccessScore, 0.50, na.rm = TRUE)\n\n# Choose movies that have a low success score\nlow_success_movies &lt;- TITLE_RATINGS |&gt;\n    filter(SuccessScore &lt; threshold) |&gt;  # Define a threshold for low success score\n    arrange(desc(numVotes)) |&gt;\n    semi_join(TITLE_BASICS, by = \"tconst\") |&gt;\n    select(tconst, primaryTitle, titleType, averageRating, numVotes, SuccessScore) |&gt;\n    head(5)\n\n# View these movies\nprint(low_success_movies)\n\n\nMovies such as Radhe, Adipurush, and Catwoman despite high vote counts, scored poorly on the success metric, reflecting their lower critical reception.\n\nChoose a prestige actor or director and confirm that they have many projects with high scores on your success metric.\n\n\n\nCode\n# Choose a known actor or director\nprestige_actor &lt;- \"Tom Cruise\"\n\n# Find the actor's nconst\nactor_nconst &lt;- NAME_BASICS |&gt;\n    filter(primaryName == prestige_actor) |&gt;\n    pull(nconst, primaryName)\n    \n\nactor_nconst\n\n\n Tom Cruise \n\"nm0000129\" \n\n\n\n\nCode\n# Find projects associated with the actor using TITLE_PRINCIPALS\nactor_projects &lt;- TITLE_PRINCIPALS |&gt;\n    filter(nconst == actor_nconst) |&gt;\n    inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n    inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n    arrange(desc(SuccessScore)) |&gt;\n    select(tconst, originalTitle, startYear, SuccessScore) |&gt;\n    distinct() |&gt;\n    slice_head(n=5)\n\n# View actor projects\nprint(actor_projects)\n\n\nPrestige Actor Validation: Tom Cruise’s projects, such as Top Gun: Maverick (2022), Edge of Tomorrow (2014), and Rain Man (1988), ranked highly on the success metric, confirming his box office success and critical praise.\n\nSuccess Threshold\n\n\n\nCode\n# Define the threshold for \"solid\" movies at the 75th percentile (or higher)\nsuccess_threshold &lt;- quantile(TITLE_RATINGS$SuccessScore, 0.75, na.rm = TRUE)\n\n# Print the threshold value\nprint(success_threshold)\n\n\n     75% \n4.902686 \n\n\nA reasonable success threshold would be in the upper quantiles of the success metric, such as the 75th percentile. Doing so ensures the movies classified as Solid are in the top quantile of the IMDb data-set."
  },
  {
    "objectID": "mp02.html#nostalgia-and-remakes",
    "href": "mp02.html#nostalgia-and-remakes",
    "title": "Mini-Project #02: The Business of Show Business",
    "section": "",
    "text": "Remake of a Classic Movie: The classic film chosen for the remake is The Great Escape (1963). With its strong IMDb rating (8.2/10) and over 200,000 votes, it fits the Action/Adventure genre. The original film’s high rating and memorable ensemble cast make it ideal for modern retelling with Tom Cruise, Chris Hemsworth, and Zendaya."
  },
  {
    "objectID": "mp02.html#elevator-pitch-from-director",
    "href": "mp02.html#elevator-pitch-from-director",
    "title": "Mini-Project #02: The Business of Show Business",
    "section": "",
    "text": "Tom Cruise, the visionary behind Mission: Impossible, and from actors Chris Hemsworth, beloved star of Thor, and Zendaya, Hollywood’s rising star from Dune, comes a timeless tale of adventure, escape, and survival—The Great Escape.\nIn this modern remake of the classic 1963 film, a group of prisoners of war plot a daring escape from a heavily fortified enemy camp. Combining intense action sequences with a stellar cast, this film is set to captivate a new generation of audiences while honoring the original masterpiece. Coming soon to theaters."
  },
  {
    "objectID": "Resume.html",
    "href": "Resume.html",
    "title": "Timbila NIKIEMA",
    "section": "",
    "text": "Lodi, New Jersey\nEmail | (646) 707-8740\n\n\n\nBARUCH COLLEGE | ZICKLIN SCHOOL OF BUSINESS\nMaster of Science – MS Quantitative Methods and Modeling\nJune 2025\nBachelor of Business Administration\nDecember 2018\nMajor: Finance, Minor: Economics\n\n\n\n\nST BARNABAS HEALTH SYSTEM\nSenior Financial Analyst\nOctober 2022 – Present\n\nPrepare monthly grant vouchers and annual budgets to external entities and monitor grant cash payments.\nAssist with monthly account analysis and the preparation of the monthly financial statement process.\nCollaborate with team members to develop the organization’s overall budget.\nReview budget proposals for completeness, accuracy, and compliance with organizational standards.\nMaintain controls over expenditures to ensure adherence to the budget.\nConduct cost-benefit analyses to assess the efficiency and effectiveness of various programs.\nAssist in year-end audit procedures; prepare work papers, inquiries, and other supporting documentation.\nCreate a consolidated budget for the entire organization, integrating various departmental budgets.\nPerform ongoing budget tool updates and adjustments as needed throughout the budgetary cycle.\nAnalyze budget and financial data to develop annual and multi-year budget estimates.\nMonitor the execution of an approved operating budget to ensure funds are properly allocated and spent timely.\nEstimate salaries and expenses based on past data and forecasts of changing costs and requirements.\nDevelop and justify an operating budget.\nMonitor expenditure of budgeted funds and compare them to expected expenditure levels.\nAnalyze trends in fund usage and recommend adjustments in program spending.\nParticipate in the development and analysis of annual and program budget submissions.\n\nNORTHWELL HEALTH\nSenior Corporate Financial Analyst\nOctober 2019 – October 2022\n\nAnalyze past results, perform variance analysis, identify trends, and make recommendations for improvements.\nMaintain proprietary databases including data integrity, timeliness of data input, and accuracy.\nDesign, develop, and modify systems and procedures to enhance departmental processing as needed.\nReport results on a monthly, quarterly, and/or annual basis.\nIncrease productivity by developing automated reporting/forecasting tools.\nRecommend actions by analyzing and interpreting data and making comparative analyses.\nIdentify and drive process improvements, including the creation of standard and ad-hoc reports.\nDevelop and support dynamic Excel-based reporting tools to enhance the reporting process.\nProvide management with ad hoc financial analysis upon request.\n\n\n\n\n\n\nBloomberg Market Concept\nLanguage: Advanced French\nComputers: Microsoft Excel, Microsoft Access, PowerPoint, Tableau, StrataJazz, Oracle Cloud, SQL Fundamentals"
  },
  {
    "objectID": "Resume.html#education",
    "href": "Resume.html#education",
    "title": "Timbila NIKIEMA",
    "section": "",
    "text": "BARUCH COLLEGE | ZICKLIN SCHOOL OF BUSINESS\nMaster of Science – MS Quantitative Methods and Modeling\nJune 2025\nBachelor of Business Administration\nDecember 2018\nMajor: Finance, Minor: Economics"
  },
  {
    "objectID": "Resume.html#experience",
    "href": "Resume.html#experience",
    "title": "Timbila NIKIEMA",
    "section": "",
    "text": "ST BARNABAS HEALTH SYSTEM\nSenior Financial Analyst\nOctober 2022 – Present\n\nPrepare monthly grant vouchers and annual budgets to external entities and monitor grant cash payments.\nAssist with monthly account analysis and the preparation of the monthly financial statement process.\nCollaborate with team members to develop the organization’s overall budget.\nReview budget proposals for completeness, accuracy, and compliance with organizational standards.\nMaintain controls over expenditures to ensure adherence to the budget.\nConduct cost-benefit analyses to assess the efficiency and effectiveness of various programs.\nAssist in year-end audit procedures; prepare work papers, inquiries, and other supporting documentation.\nCreate a consolidated budget for the entire organization, integrating various departmental budgets.\nPerform ongoing budget tool updates and adjustments as needed throughout the budgetary cycle.\nAnalyze budget and financial data to develop annual and multi-year budget estimates.\nMonitor the execution of an approved operating budget to ensure funds are properly allocated and spent timely.\nEstimate salaries and expenses based on past data and forecasts of changing costs and requirements.\nDevelop and justify an operating budget.\nMonitor expenditure of budgeted funds and compare them to expected expenditure levels.\nAnalyze trends in fund usage and recommend adjustments in program spending.\nParticipate in the development and analysis of annual and program budget submissions.\n\nNORTHWELL HEALTH\nSenior Corporate Financial Analyst\nOctober 2019 – October 2022\n\nAnalyze past results, perform variance analysis, identify trends, and make recommendations for improvements.\nMaintain proprietary databases including data integrity, timeliness of data input, and accuracy.\nDesign, develop, and modify systems and procedures to enhance departmental processing as needed.\nReport results on a monthly, quarterly, and/or annual basis.\nIncrease productivity by developing automated reporting/forecasting tools.\nRecommend actions by analyzing and interpreting data and making comparative analyses.\nIdentify and drive process improvements, including the creation of standard and ad-hoc reports.\nDevelop and support dynamic Excel-based reporting tools to enhance the reporting process.\nProvide management with ad hoc financial analysis upon request."
  },
  {
    "objectID": "Resume.html#skills",
    "href": "Resume.html#skills",
    "title": "Timbila NIKIEMA",
    "section": "",
    "text": "Bloomberg Market Concept\nLanguage: Advanced French\nComputers: Microsoft Excel, Microsoft Access, PowerPoint, Tableau, StrataJazz, Oracle Cloud, SQL Fundamentals"
  },
  {
    "objectID": "mp02.html#in-this-modern-remake-of-the-classic-1963-film-a-group-of-prisoners-of-war-plot-a-daring-escape-from-a-heavily-fortified-enemy-camp.-combining-intense-action-sequences-with-a-stellar-cast-this-film-is-set-to-captivate-a-new-generation-of-audiences-while-honoring-the-original-masterpiece.-coming-soon-to-theaters.",
    "href": "mp02.html#in-this-modern-remake-of-the-classic-1963-film-a-group-of-prisoners-of-war-plot-a-daring-escape-from-a-heavily-fortified-enemy-camp.-combining-intense-action-sequences-with-a-stellar-cast-this-film-is-set-to-captivate-a-new-generation-of-audiences-while-honoring-the-original-masterpiece.-coming-soon-to-theaters.",
    "title": "Mini-Project #02: The Business of Show Business",
    "section": "In this modern remake of the classic 1963 film, a group of prisoners of war plot a daring escape from a heavily fortified enemy camp. Combining intense action sequences with a stellar cast, this film is set to captivate a new generation of audiences while honoring the original masterpiece. Coming soon to theaters.",
    "text": "In this modern remake of the classic 1963 film, a group of prisoners of war plot a daring escape from a heavily fortified enemy camp. Combining intense action sequences with a stellar cast, this film is set to captivate a new generation of audiences while honoring the original masterpiece. Coming soon to theaters."
  },
  {
    "objectID": "mp02.html",
    "href": "mp02.html",
    "title": "Mini-Project #02: The Business of Show Business",
    "section": "",
    "text": "This report outlines the analysis of IMDb data to determine the best genre, actors, and directors for a successful new movie project. We used a structured approach to filter, clean, and analyze IMDb data to identify trends and define a custom metric for success. The project involved using R to handle large data files, performing tasks like correcting column types, sub-sampling, and developing a success metric based on IMDb ratings and vote counts. Finally, we provided a movie proposal based on key personnel and a chosen genre, supported by data-driven insights.\n\n\n\nIMDb provides extensive data, which required careful sub-sampling and filtering to make it manageable. To achieve this, we will take the following steps:\nStep 1: Download the data from IMDb and create the following tables:\n\nNAME_BASICS: contains information about people (actors, directors, writers, etc.) in the IMDb database.\nTITLE_BASICS: contains basic information about movies, TV shows, and other titles listed in IMDb.\nTITLE_EPISODES: contains information specific to individual TV episodes.\nTITLE_RATINGS: contains IMDb ratings for titles.\nTITLE_CREW: contains information about the director(s) and writer(s) for each title.\nTITLE_PRINCIPALS: contains information about the key cast and crew involved in a title.\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(stringr)\nlibrary(grid)\nlibrary(shadowtext)\nlibrary(ggplot2)\nlibrary(gganimate)\nlibrary(plotly)\nlibrary(treemap)\nlibrary(gifski)\nlibrary(DT)\n\nget_imdb_file &lt;- function(fname){\n    BASE_URL &lt;- \"https://datasets.imdbws.com/\"\n    fname_ext &lt;- paste0(fname, \".tsv.gz\")\n    if(!file.exists(fname_ext)){\n        FILE_URL &lt;- paste0(BASE_URL, fname_ext)\n        download.file(FILE_URL, \n                      destfile = fname_ext)\n    }\n    as.data.frame(readr::read_tsv(fname_ext, lazy=FALSE))\n}\n\nNAME_BASICS      &lt;- get_imdb_file(\"name.basics\")\nTITLE_BASICS     &lt;- get_imdb_file(\"title.basics\")\nTITLE_EPISODES   &lt;- get_imdb_file(\"title.episode\")\nTITLE_RATINGS    &lt;- get_imdb_file(\"title.ratings\")\nTITLE_CREW       &lt;- get_imdb_file(\"title.crew\")\nTITLE_PRINCIPALS &lt;- get_imdb_file(\"title.principals\")\n\n\nStep 2: Let’s throw out any title with less than 100 ratings. It’s not too hard to see that this drops about 75% of the entire data set.\n\n\nCode\nTITLE_RATINGS |&gt;\n    pull(numVotes) |&gt;\n    quantile()\n\n\n     0%     25%     50%     75%    100% \n      5      11      26     100 2953606 \n\n\nStep 3: Filtering People: The NAME_BASICS table was filtered to include only those with at least two known for credits.\n\n\nCode\nNAME_BASICS &lt;- NAME_BASICS |&gt; \n    filter(str_count(knownForTitles, \",\") &gt; 1)\n\n\nStep 3: Title Filtering: Titles with fewer than 100 IMDb ratings will be removed, retaining only more widely recognized movies.\n\n\nCode\n# Let's drop movie titles with less than 100 votes\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n    filter(numVotes &gt;= 100)\n\n\nStep 4: Joining Tables: A semi-join on the filtered TITLE_RATINGS table will be used to filter the TITLE_BASICS, TITLE_CREW, TITLE_EPISODES, and TITLE_PRINCIPALS tables.\n\n\nCode\nTITLE_BASICS &lt;- TITLE_BASICS |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\n\nTITLE_CREW &lt;- TITLE_CREW |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\n\nTITLE_EPISODES_1 &lt;- TITLE_EPISODES |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(tconst == tconst))\nTITLE_EPISODES_2 &lt;- TITLE_EPISODES |&gt;\n    semi_join(TITLE_RATINGS, \n              join_by(parentTconst == tconst))\n\nTITLE_EPISODES &lt;- bind_rows(TITLE_EPISODES_1,\n                            TITLE_EPISODES_2) |&gt;\n    distinct()\n\nTITLE_PRINCIPALS &lt;- TITLE_PRINCIPALS |&gt;\n    semi_join(TITLE_RATINGS, join_by(tconst == tconst))\n\n\nrm(TITLE_EPISODES_1)\nrm(TITLE_EPISODES_2)\n\n\nStep 5: Using a combination of mutate and the coercion functions as.numeric and as.logical to correct the data type for all the tables.\n\n\nCode\n# Correct the column types for NAME_BASICS\nNAME_BASICS &lt;- NAME_BASICS |&gt;\n    mutate(birthYear = as.numeric(birthYear), # Numeric\n           deathYear = as.numeric(deathYear)) # Numeric\n\n# Correct the column types for TITLE_BASICS\nTITLE_BASICS &lt;- TITLE_BASICS |&gt;\n    mutate(\n        tconst = as.character(tconst),  # ID should remain as character\n        titleType = as.character(titleType),  # Character\n        primaryTitle = as.character(primaryTitle),  # Character\n        originalTitle = as.character(originalTitle),  # Character\n        isAdult = as.logical(isAdult),  # Boolean\n        startYear = as.numeric(startYear),  # Numeric\n        endYear = as.numeric(endYear),  # Numeric\n        runtimeMinutes = as.numeric(runtimeMinutes),  # Numeric\n        genres = as.character(genres)  # Character\n    )\n\n# Correct the column types for TITLE_RATINGS\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n    mutate(\n        tconst = as.character(tconst),  # ID should remain as character\n        averageRating = as.numeric(averageRating),  # Numeric\n        numVotes = as.numeric(numVotes)  # Numeric\n    )\n\n# Correct the column types for TITLE_CREW\nTITLE_CREW &lt;- TITLE_CREW |&gt;\n    mutate(\n        tconst = as.character(tconst),  # ID should remain as character\n        directors = as.character(directors),  # Character\n        writers = as.character(writers)  # Character\n    )\n\n# Correct the column types for TITLE_EPISODES\nTITLE_EPISODES &lt;- TITLE_EPISODES |&gt;\n    mutate(\n        tconst = as.character(tconst),  # ID should remain as character\n        parentTconst = as.character(parentTconst),  # Character\n        seasonNumber = as.numeric(seasonNumber),  # Numeric\n        episodeNumber = as.numeric(episodeNumber)  # Numeric\n    )\n\n# Correct the column types for TITLE_PRINCIPALS\nTITLE_PRINCIPALS &lt;- TITLE_PRINCIPALS |&gt;\n    mutate(\n        tconst = as.character(tconst),  # ID should remain as character\n        ordering = as.numeric(ordering),  # Numeric\n        nconst = as.character(nconst),  # Character\n        category = as.character(category),  # Character\n        job = as.character(job),  # Character\n        characters = as.character(characters)  # Character\n    )\n\n\nStep 6: Separating fields with combined multiple values.\n\nglimpse(NAME_BASICS)\n\nRows: 3,190,744\nColumns: 6\n$ nconst            &lt;chr&gt; \"nm0000001\", \"nm0000002\", \"nm0000003\", \"nm0000004\", …\n$ primaryName       &lt;chr&gt; \"Fred Astaire\", \"Lauren Bacall\", \"Brigitte Bardot\", …\n$ birthYear         &lt;dbl&gt; 1899, 1924, 1934, 1949, 1918, 1915, 1899, 1924, 1925…\n$ deathYear         &lt;dbl&gt; 1987, 2014, NA, 1982, 2007, 1982, 1957, 2004, 1984, …\n$ primaryProfession &lt;chr&gt; \"actor,miscellaneous,producer\", \"actress,soundtrack,…\n$ knownForTitles    &lt;chr&gt; \"tt0050419,tt0072308,tt0053137,tt0027125\", \"tt003738…\n\n\nWe can see that in the NAME_BASICS table, both the primaryProfession and knownForTitles columns have combine multiple values. To answer some of the questions, we will need use separate_longer_delim to split the values.\n\n\nCode\nNAME_BASICS |&gt; \n    separate_longer_delim(knownForTitles, \",\") |&gt; \n    separate_longer_delim(primaryProfession, \",\") |&gt; \n    slice_head(n = 10)\n\n\nNow that we have successfully processed the dataset by significantly reducing its size, it is now more manageable for the subsequent analysis.\n\n\n\n\nHow many movies are in our data set? How many TV series? How many TV episodes?\n\n\n\nCode\nTITLE_SUMMARY &lt;- TITLE_BASICS |&gt;\n    filter( titleType %in% c(\"movie\", \"tvSeries\", \"tvEpisode\")) |&gt;\n    group_by(titleType) |&gt;\n    summarize(count = n())|&gt;\n    arrange(desc(count))\n\ndatatable(setNames(TITLE_SUMMARY, c(\"Type\", \"Total\")),\n          options = list(pageLength = 10, autoWidth = TRUE),\n          caption = \"Table 1: Number of Movies, TV series, and TV episodes\")\n\n\nUsing filters applied on the TITLE_BASICS table, we found:\n\nMovies: 132,335\nTV Series: 30,025\nTV Episodes: 156,904\n\n\nWho is the oldest living person in our data set?\n\n\n\nCode\npeople_after_1917_alive &lt;- NAME_BASICS |&gt;\n    filter(birthYear &gt; 1917, is.na(deathYear)) |&gt; # Filter for birthYear &gt; 1917 and deathYear is NA\n    arrange(birthYear) |&gt;\n    slice_head(n = 1)\n\nprint(people_after_1917_alive)\n\n\nThe oldest living person, based on the NAME_BASICS table, is Orest Alikin, born in 1918.\n\nThere is one TV Episode in this data set with a perfect 10/10 rating and 200,000 IMDb ratings. What is it? What series does it belong to?\n\nLet us find the TV Episode with the perfect rating and 200,000 IMDb ratings.First, we need the information from the TITLE_RATINGS and TITLE_BASICS. Then, we will find the TV episode with 10/10 rating and more 200,000 votes.\n\n\nCode\nperfect_episode &lt;- TITLE_RATINGS |&gt;\n    filter(averageRating == 10, numVotes &gt;= 200000) |&gt;\n    inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n    filter(titleType == \"tvEpisode\") |&gt;\n    select(tconst, primaryTitle, titleType, genres, startYear, averageRating, numVotes)\n\nperfect_episode\n\n\nThe TV episode is Ozymandias from Breaking Bad (Season 5, Episode 14), with over 200,000 votes and a perfect score.\n\nWhat four projects is the actor Mark Hammill most known for?\n\n\n\nCode\n# Find Mark Hamill in the NAME_BASICS table\nmark_hamill_titles &lt;- NAME_BASICS |&gt;\n    filter(primaryName == \"Mark Hamill\") |&gt;\n    select(knownForTitles) |&gt;\n    separate_rows(knownForTitles, sep = \",\") # Split the knownForTitles into individual rows\n\n# Join with TITLE_BASICS to get the details of the titles\nmark_hamill_projects &lt;- mark_hamill_titles |&gt;\n    inner_join(TITLE_BASICS, by = c(\"knownForTitles\" = \"tconst\")) |&gt;\n    select(primaryTitle, titleType, startYear)\n\n# View the result\nmark_hamill_projects\n\n\nMark Hamill is most known for:\n\nStar Wars: Episode IV - A New Hope (1977)\nStar Wars: Episode VIII - The Last Jedi (2017)\nStar Wars: Episode V - The Empire Strikes Back (1980)\nStar Wars: Episode VI - Return of the Jedi (1983)\n\n\nWhat TV series, with more than 12 episodes, has the highest average rating?\n\n\n\nCode\n# Step 1: Filter the TITLE_BASICS table to get only TV series and episodes\ntv_series &lt;- TITLE_BASICS |&gt;\n    filter(titleType == \"tvSeries\")\n\ntv_episodes &lt;- TITLE_BASICS |&gt;\n    filter(titleType == \"tvEpisode\")\n\n# Step 2: Join the episodes with their parent TV series using TITLE_EPISODES\ntv_series_episodes &lt;- TITLE_EPISODES |&gt;\n    inner_join(tv_episodes, by = c(\"tconst\" = \"tconst\")) |&gt;\n    inner_join(tv_series, by = c(\"parentTconst\" = \"tconst\"))\n\n# Step 3: Join with the TITLE_RATINGS to get the ratings for the episodes\nepisode_ratings &lt;- tv_series_episodes |&gt;\n    inner_join(TITLE_RATINGS, by = c(\"tconst\" = \"tconst\"))\n\n# Step 4: Calculate the number of episodes and average rating for each TV series\nseries_ratings &lt;- episode_ratings |&gt;\n    group_by(parentTconst) |&gt;\n    summarize(numEpisodes = n(), avgRating = mean(averageRating, na.rm = TRUE)) |&gt;\n    filter(numEpisodes &gt; 12) |&gt;\n    arrange(desc(avgRating))\n\n# Step 5: Join with TITLE_BASICS to get the series name\nbest_tv_series &lt;- series_ratings |&gt;\n    inner_join(tv_series, by = c(\"parentTconst\" = \"tconst\")) |&gt;\n    select(primaryTitle, numEpisodes, startYear, endYear, avgRating) |&gt;\n    slice(1)\n\n# View the result\nbest_tv_series\n\n\nKavya - Ek Jazbaa, Ek Junoon (2023-NA) holds the highest average IMDb rating (9.75) among series with 113 episodes.\n\nIs it true that episodes from later seasons of Happy Days have lower average ratings than the early seasons?\n\n\n\nCode\n# Step 1: Identify the \"Happy Days\" series in TITLE_BASICS\nhappy_days_series &lt;- TITLE_BASICS |&gt;\n    filter(primaryTitle == \"Happy Days\", startYear == 1974) |&gt;\n    select(tconst, primaryTitle, startYear)\n\n# Step 2: Get all episodes of \"Happy Days\" using TITLE_EPISODES\nhappy_days_episodes &lt;- TITLE_EPISODES |&gt;\n    filter(parentTconst == happy_days_series$tconst) |&gt;\n    inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n    select(tconst, seasonNumber, primaryTitle, episodeNumber)\n\n# Step 3: Get ratings for each episode\nhappy_days_ratings &lt;- happy_days_episodes |&gt;\n    inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n    filter(!is.na(seasonNumber))  # Filter out episodes with missing season information\n\n# Step 4: Calculate the average rating for each season\nseason_ratings &lt;- happy_days_ratings |&gt;\n    group_by(seasonNumber) |&gt;\n    summarize(avgRating = mean(averageRating, na.rm = TRUE), numEpisodes = n()) |&gt;\n    arrange(seasonNumber)\n\n# Step 5: Compare the average ratings of early and later seasons\n# We'll split into early (e.g., seasons 1-4) and later (e.g., seasons 5+)\nearly_seasons &lt;- season_ratings |&gt;\n    filter(seasonNumber &lt;= 4) |&gt;\n    summarize(early_avg = mean(avgRating, na.rm = TRUE))\n\nlater_seasons &lt;- season_ratings |&gt;\n    filter(seasonNumber &gt;= 5) |&gt;\n    summarize(later_avg = mean(avgRating, na.rm = TRUE))\n\n# Combine both results into one data frame\ncombined_ratings &lt;- bind_cols(early_seasons, later_seasons)\n\nprint(combined_ratings)\n\n\nOur analysis confirms that the average ratings of episodes in later seasons (6.58) are lower than those of the earlier seasons (7.60).\n\n\n\nIn order to draft a successful proposal for a new movie, we need a success metric that effectively evaluates both the quality (as reflected by average ratings) and popularity (as measured by the number of votes) of a film, ensuring that our decision is data-driven and aimed at maximizing audience appeal and potential profitability.\n\n\nCode\n# Success Metric\nTITLE_RATINGS &lt;- TITLE_RATINGS |&gt;\n    mutate(SuccessScore = (averageRating * log(numVotes)) / 10) |&gt;\n    arrange(desc(SuccessScore)) |&gt;\n    inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n    select(tconst, primaryTitle, titleType, numVotes, averageRating, SuccessScore)\n\nhead(TITLE_RATINGS)\n\n\n\nChoose the top 5-10 movies on your metric and confirm that they were indeed box office successes.\n\n\n\nCode\n# Join TITLE_RATINGS with TITLE_BASICS, filter for movies, and select top 10 based on SuccessScore\ntop_movies &lt;- TITLE_RATINGS |&gt;\n    arrange(desc(SuccessScore)) |&gt;\n    select(tconst, averageRating, numVotes, SuccessScore) |&gt;\n    inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n    filter(titleType == \"movie\") |&gt;\n    select(tconst, primaryTitle, titleType, SuccessScore) |&gt;\n    head(10)\n\n# View top movies\nprint(top_movies)\n\n\nThe top movies based on this metric includes The Shawshank Redemptiom, The Dark Knight, and The Godfather - all recognized as major box office hits.\n\nChoose 3-5 movies with large numbers of IMDb votes that score poorly on your success metric and confirm that they are indeed of low quality.\n\n\n\nCode\n# Define a threshold for low success score\nthreshold &lt;- quantile(TITLE_RATINGS$SuccessScore, 0.50, na.rm = TRUE)\n\n# Choose movies that have a low success score\nlow_success_movies &lt;- TITLE_RATINGS |&gt;\n    filter(SuccessScore &lt; threshold) |&gt;  # Define a threshold for low success score\n    arrange(desc(numVotes)) |&gt;\n    semi_join(TITLE_BASICS, by = \"tconst\") |&gt;\n    select(tconst, primaryTitle, titleType, averageRating, numVotes, SuccessScore) |&gt;\n    head(5)\n\n# View these movies\nprint(low_success_movies)\n\n\nMovies such as Radhe, Adipurush, and Catwoman despite high vote counts, scored poorly on the success metric, reflecting their lower critical reception.\n\nChoose a prestige actor or director and confirm that they have many projects with high scores on your success metric.\n\n\n\nCode\n# Choose a known actor or director\nprestige_actor &lt;- \"Tom Cruise\"\n\n# Find the actor's nconst\nactor_nconst &lt;- NAME_BASICS |&gt;\n    filter(primaryName == prestige_actor) |&gt;\n    pull(nconst, primaryName)\n    \n\nactor_nconst\n\n\n Tom Cruise \n\"nm0000129\" \n\n\n\n\nCode\n# Find projects associated with the actor using TITLE_PRINCIPALS\nactor_projects &lt;- TITLE_PRINCIPALS |&gt;\n    filter(nconst == actor_nconst) |&gt;\n    inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n    inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n    arrange(desc(SuccessScore)) |&gt;\n    select(tconst, originalTitle, startYear, SuccessScore) |&gt;\n    distinct() |&gt;\n    slice_head(n=5)\n\n# View actor projects\nprint(actor_projects)\n\n\nPrestige Actor Validation: Tom Cruise’s projects, such as Top Gun: Maverick (2022), Edge of Tomorrow (2014), and Rain Man (1988), ranked highly on the success metric, confirming his box office success and critical praise.\n\nSuccess Threshold\n\n\n\nCode\n# Define the threshold for \"solid\" movies at the 75th percentile (or higher)\nsuccess_threshold &lt;- quantile(TITLE_RATINGS$SuccessScore, 0.75, na.rm = TRUE)\n\n# Print the threshold value\nprint(success_threshold)\n\n\n     75% \n4.902686 \n\n\nA reasonable success threshold would be in the upper quantiles of the success metric, such as the 75th percentile. Doing so ensures the movies classified as Solid are in the top quantile of the IMDb data-set.\n\n\n\nNow that you have a working proxy for success, it’s time to look at trends in success over time. Let’s join TITLE_BASICS and TITLE_RATINGS to bring in genres and release years to create a Decade column then using our success threshold to filter for successful movies.\n\n\nCode\n# Join TITLE_BASICS and TITLE_RATINGS \nmovies_with_genres &lt;- TITLE_BASICS |&gt;\n    select(tconst, primaryTitle, genres, startYear) |&gt;\n    inner_join(TITLE_RATINGS, by = \"tconst\") |&gt; \n    filter(!is.na(genres), !is.na(startYear))  # Remove missing genres or years\n\n# Creating a decade column (e.g., 1990s, 2000s, 2010s)\nmovies_with_genres &lt;- movies_with_genres |&gt;\n    mutate(decade = floor(as.numeric(startYear) / 10) * 10)\n\n# Filter for successful movies\nsuccessful_movies &lt;- movies_with_genres |&gt;\n    filter(SuccessScore &gt; success_threshold)\n\n# Count successful movies by genre and decade\nsuccess_by_genre_decade &lt;- successful_movies |&gt;\n    separate_rows(genres, sep = \",\") |&gt;\n    group_by(genres, decade) |&gt;\n    summarize(success_count = n()) |&gt;\n    arrange(desc(success_count))\n\n\n\nWhat was the genre with the most “successes” in each decade?\n\nThe graph below shows the success count of genres by decade, highlighting the rise and the relative decline of Drama in recent years.\n\n\nCode\nlibrary(gganimate)\n\n# Find the genre with the most successes in each decade\ntop_genre_each_decade &lt;- success_by_genre_decade |&gt;\n    group_by(decade) |&gt;\n    filter(genres != \"\\\\N\" & !is.na(genres)) |&gt;\n    slice_max(success_count, n = 1) |&gt;\n    arrange(desc(decade), desc(success_count))\n\np &lt;- ggplot(top_genre_each_decade, aes(x = decade, y = success_count, color = genres)) +\n  geom_point(size = 5, alpha = 0.7, position = position_jitter(width = 0.3, height = 0)) +\n  labs(title = \"Top Genres by Success in Each Decade: {closest_state}\",\n       x = \"Decade\",\n       y = \"Success Count\") +\n  theme_minimal() + \n  scale_color_brewer(palette = \"Set2\") +\n  ylim(0, 23000) +\n  theme(legend.position = \"bottom\")\n\n# Add animation transition\np_anim &lt;- p + \n  transition_states(decade, transition_length = 2, state_length = 1) +\n  shadow_mark() +\n  ease_aes('linear')\n\n# Animate the scatter plot\nanimate(p_anim, nframes = 100, fps = 10)\n\n\n\n\n\n\n\n\n\nThe Drama genre has the highest success rate historically but has seen a relative decline in recent years.\n\nWhat genre consistently has the most “successes”? What genre used to reliably produced “successes” and has fallen out of favor?\n\nAs previously shown, Drama is the leading genre with 53,390 success over the success_threshold.\n\n\nCode\n# Find the genre with the most successes across all decades\ntotal_success_by_genre &lt;- success_by_genre_decade |&gt;\n    group_by(genres) |&gt;\n    summarize(total_success_count = sum(success_count)) |&gt;\n    arrange(desc(total_success_count)) |&gt;\n    slice(1)\n\ntotal_success_by_genre\n\n\n\n\nCode\n# Analyze the trends by comparing the success count in earlier vs recent decades\n# Split into early (before 2000) and recent (2000 and after) decades\nearly_genre_success &lt;- success_by_genre_decade |&gt;\n    filter(decade &lt; 2000) |&gt;\n    group_by(genres) |&gt;\n    summarize(early_success_count = sum(success_count))\n\nrecent_genre_success &lt;- success_by_genre_decade |&gt;\n    filter(decade &gt;= 2000) |&gt;\n    group_by(genres) |&gt;\n    summarize(recent_success_count = sum(success_count))\n\n# Combine the early and recent success counts to compare\ngenre_success_trend &lt;- early_genre_success |&gt;\n    inner_join(recent_genre_success, by = \"genres\", suffix = c(\"_early\", \"_recent\")) |&gt;\n    mutate(success_drop = early_success_count - recent_success_count) |&gt;\n    filter(genres != \"\\\\N\" & !is.na(genres)) |&gt;\n    arrange(desc(success_drop)) |&gt;\n    slice(1)\n\nprint(genre_success_trend)\n\n\nThe data reveals a noticeable decline in the number of successful Western films over time, with a drop of 134 films from the earlier period to the more recent one. This suggests a decreasing popularity or a shift in audience preferences away from the Western genre in recent years\n\nWhat genre has produced the most “successes” since 2010? Does it have the highest success rate or does it only have a large number of successes because there are many productions in that genre?\n\n\n\nCode\n# Filter for movies released since 2010\nsuccess_since_2010 &lt;- success_by_genre_decade |&gt;\n    filter(decade &gt;= 2010) |&gt;\n    group_by(genres) |&gt;\n    summarize(success_count = sum(success_count), .groups = 'drop')\n\n# Count total productions in each genre since 2010\ntotal_productions_since_2010 &lt;- movies_with_genres |&gt;\n    filter(startYear &gt;= 2010) |&gt;\n    separate_rows(genres, sep = \",\") |&gt;\n    group_by(genres) |&gt;\n    summarize(total_productions = n(), .groups = 'drop')\n\n# Combine the success counts with total productions to calculate the success rate\ngenre_success_rate &lt;- success_since_2010 |&gt;\n    inner_join(total_productions_since_2010, by = \"genres\") |&gt;\n    mutate(success_rate = success_count / total_productions) |&gt;\n    filter(success_count &gt;= 5000, genres != \"\\\\N\" & !is.na(genres)) |&gt;\n    arrange(desc(success_count))\n\n# View the genres with their success counts and success rates\nprint(genre_success_rate)\n\n\nSince 2010, Drama has the most successful productions primarily due to its large number of total productions. While its success rate of 33.9% is fairly strong, it is not the highest compared to other genres like Adventure and Action, which both have success rates around 40%. This indicates that Drama’s high number of successes is largely due to the volume of productions in the genre, rather than each individual production having the highest probability of success.\nThus, Drama benefits from sheer volume, while genres like Action and Adventure, though producing fewer total successes, have a higher likelihood of success relative to the number of productions in that genre.\n\nWhat genre has become more popular in recent years?\n\n\n\nCode\n# Compare success counts between earlier decades and 2010s\ngrowth_in_genre &lt;- success_by_genre_decade |&gt;\n    filter(genres != \"\\\\N\" & !is.na(genres), decade %in% c(1990, 2000, 2010)) |&gt;\n    spread(decade, success_count, fill = 0) |&gt;\n    mutate(growth = `2010` - `1990`) |&gt;\n    arrange(desc(growth))\n\ngrowth_in_genre_long &lt;- success_by_genre_decade |&gt;\n  filter(genres != \"\\\\N\" & !is.na(genres), decade %in% c(1990, 2000, 2010)) |&gt;\n  arrange(desc(success_count))\n\n# Create the animated bar chart\np &lt;- ggplot(growth_in_genre_long, aes(x = reorder(genres, success_count), y = success_count, fill = genres)) +\n  geom_bar(stat = \"identity\", show.legend = FALSE) +\n  geom_text(aes(label = scales::comma(round(success_count, 0))),  # Add labels without decimals\n            hjust = -0.2, size = 4) +  # Adjust position and size of labels\n  coord_flip() +\n  labs(title = \"Growth in Genre Success (2010s vs 1990s): {closest_state}\",\n       x = \"Genres\",\n       y = \"Growth\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 0, hjust = 1)) +  # Ensure x-axis labels are horizontal\n  transition_states(decade, transition_length = 2, state_length = 1) +\n  ease_aes('linear') +\n  ylim(0, 30000)\n\n# Animate the plot\nanimate(p, nframes = 100, fps = 10)\n\n\n\n\n\n\n\n\n\nDrama has become the most popular genre in recent years, with a significant growth of successful productions from 1990 to 2010. This is followed by Comedy, Action, Crime, and Adventure, all of which also experienced significant growth in success over this period. These genres have consistently attracted larger audiences and produced more successful movies over the past few decades, showing a trend of increasing popularity.\n\n\n\n\n\nCode\n# Filter for action movies that are successful\nsuccessful_action_movies &lt;- TITLE_BASICS |&gt;\n    filter(str_detect(genres, \"Action\")) |&gt;  # Only action genre\n    inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n    filter(SuccessScore &gt; success_threshold)  # Use success threshold from earlier\n\n# Find the actors in these successful movies\nsuccessful_actors &lt;- TITLE_PRINCIPALS |&gt;\n    filter(tconst %in% successful_action_movies$tconst) |&gt;\n    inner_join(NAME_BASICS, by = \"nconst\") |&gt;  # Get actor names\n    filter(category == \"actor\") |&gt;  # Filter for actors\n    group_by(primaryName) |&gt;\n    summarize(success_count = n()) |&gt;\n    arrange(desc(success_count)) |&gt;  # Sort by success count\n    head(10)  # Limit to top 10 actors\n\n# Find the directors in these successful movies\n# Split the 'directors' column in TITLE_CREW to separate individual director nconsts\nlibrary(tidyr)\n\nsuccessful_directors &lt;- TITLE_CREW |&gt;\n    filter(tconst %in% successful_action_movies$tconst) |&gt;  # Only action genre movies\n    separate_rows(directors, sep = \",\") |&gt;  # Split the directors column by commas\n    inner_join(NAME_BASICS, by = c(\"directors\" = \"nconst\")) |&gt;  # Join with NAME_BASICS\n    group_by(primaryName) |&gt;  # Group by director name\n    summarize(success_count = n()) |&gt;  # Count successful movies\n    arrange(desc(success_count)) |&gt;  # Sort by success count\n    head(10)  # Limit to top 5 directors\n\n\n\n\nCode\npd &lt;- ggplot(successful_directors, aes(x = reorder(primaryName, success_count), y = success_count, color = primaryName)) +\n  geom_point(size = 5, alpha = 0.7) +\n  labs(title = \"Top Successful Directors in Action Movies: {closest_state}\",\n       x = \"Directors\",\n       y = \"Success Count\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),  # Tilt x-axis labels for readability\n        legend.position = \"none\")\n\n# Add animation\np_directors_anim &lt;- pd +\n  transition_states(primaryName, transition_length = 2, state_length = 1) +\n  shadow_mark() +\n  ease_aes('linear')\n\n# Animate the scatter plot\nanimate(p_directors_anim, nframes = 100, fps = 10)\n\n\n\n\n\n\n\n\n\n\n\nCode\npa &lt;- ggplot(successful_actors, aes(x = reorder(primaryName, success_count), y = success_count, color = primaryName)) +\n  geom_point(size = 5, alpha = 0.7) +\n  labs(title = \"Top Successful Actors in Action Movies: {closest_state}\",\n       x = \"Actors\",\n       y = \"Success Count\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),  # Tilt x-axis labels\n        legend.position = \"none\")\n\n# Add animation\np_actors_anim &lt;- pa +\n  transition_states(primaryName, transition_length = 2, state_length = 1) +\n  shadow_mark() +\n  ease_aes('linear')\n\n# Animate the scatter plot\nanimate(p_actors_anim, nframes = 100, fps = 10)\n\n\n\n\n\n\n\n\n\nBased on these insights, Action/Adventure was selected as the genre for the proposed movie.\nKey Personnel For the project, the following key personnel were selected:\n\nTom Cruise (Director): Cruise, known for his success both as an actor and producer, has a proven track record in the Action genre, with blockbusters like Top Gun: Maverick (2022) and Mission: Impossible series.\nChris Hemsworth (Actor): Hemsworth, famous for his role in Thor and the Avengers series, brings strong action credentials and fan appeal.\nZendaya (Actor): As an up-and-coming talent, Zendaya’s performances in Dune and Spider-Man: No Way Home showcase her versatility and rising star power.\n\n\n\n\nRemake of a Classic Movie: The classic film chosen for the remake is The Great Escape (1963). With its strong IMDb rating (8.2/10) and over 200,000 votes, it fits the Action/Adventure genre. The original film’s high rating and memorable ensemble cast make it ideal for modern retelling with Tom Cruise, Chris Hemsworth, and Zendaya.\n\n\n\nTom Cruise, the visionary behind Mission: Impossible, and from actors Chris Hemsworth, beloved star of Thor, and Zendaya, Hollywood’s rising star from Dune, comes a timeless tale of adventure, escape, and survival—The Great Escape.\nIn this modern remake of the classic 1963 film, a group of prisoners of war plot a daring escape from a heavily fortified enemy camp. Combining intense action sequences with a stellar cast, this film is set to captivate a new generation of audiences while honoring the original masterpiece. Coming soon to theaters."
  },
  {
    "objectID": "mp02.html#overview",
    "href": "mp02.html#overview",
    "title": "Mini-Project #02: The Business of Show Business",
    "section": "",
    "text": "This report outlines the analysis of IMDb data to determine the best genre, actors, and directors for a successful new movie project. We used a structured approach to filter, clean, and analyze IMDb data to identify trends and define a custom metric for success. The project involved using R to handle large data files, performing tasks like correcting column types, sub-sampling, and developing a success metric based on IMDb ratings and vote counts. Finally, we provided a movie proposal based on key personnel and a chosen genre, supported by data-driven insights."
  },
  {
    "objectID": "mp02.html#examining-success-by-genre-and-decade",
    "href": "mp02.html#examining-success-by-genre-and-decade",
    "title": "Mini-Project #02: The Business of Show Business",
    "section": "",
    "text": "Now that you have a working proxy for success, it’s time to look at trends in success over time. Let’s join TITLE_BASICS and TITLE_RATINGS to bring in genres and release years to create a Decade column then using our success threshold to filter for successful movies.\n\n\nCode\n# Join TITLE_BASICS and TITLE_RATINGS \nmovies_with_genres &lt;- TITLE_BASICS |&gt;\n    select(tconst, primaryTitle, genres, startYear) |&gt;\n    inner_join(TITLE_RATINGS, by = \"tconst\") |&gt; \n    filter(!is.na(genres), !is.na(startYear))  # Remove missing genres or years\n\n# Creating a decade column (e.g., 1990s, 2000s, 2010s)\nmovies_with_genres &lt;- movies_with_genres |&gt;\n    mutate(decade = floor(as.numeric(startYear) / 10) * 10)\n\n# Filter for successful movies\nsuccessful_movies &lt;- movies_with_genres |&gt;\n    filter(SuccessScore &gt; success_threshold)\n\n# Count successful movies by genre and decade\nsuccess_by_genre_decade &lt;- successful_movies |&gt;\n    separate_rows(genres, sep = \",\") |&gt;\n    group_by(genres, decade) |&gt;\n    summarize(success_count = n()) |&gt;\n    arrange(desc(success_count))\n\n\n\nWhat was the genre with the most “successes” in each decade?\n\nThe graph below shows the success count of genres by decade, highlighting the rise and the relative decline of Drama in recent years.\n\n\nCode\nlibrary(gganimate)\n\n# Find the genre with the most successes in each decade\ntop_genre_each_decade &lt;- success_by_genre_decade |&gt;\n    group_by(decade) |&gt;\n    filter(genres != \"\\\\N\" & !is.na(genres)) |&gt;\n    slice_max(success_count, n = 1) |&gt;\n    arrange(desc(decade), desc(success_count))\n\np &lt;- ggplot(top_genre_each_decade, aes(x = decade, y = success_count, color = genres)) +\n  geom_point(size = 5, alpha = 0.7, position = position_jitter(width = 0.3, height = 0)) +\n  labs(title = \"Top Genres by Success in Each Decade: {closest_state}\",\n       x = \"Decade\",\n       y = \"Success Count\") +\n  theme_minimal() + \n  scale_color_brewer(palette = \"Set2\") +\n  ylim(0, 23000) +\n  theme(legend.position = \"bottom\")\n\n# Add animation transition\np_anim &lt;- p + \n  transition_states(decade, transition_length = 2, state_length = 1) +\n  shadow_mark() +\n  ease_aes('linear')\n\n# Animate the scatter plot\nanimate(p_anim, nframes = 100, fps = 10)\n\n\n\n\n\n\n\n\n\nThe Drama genre has the highest success rate historically but has seen a relative decline in recent years.\n\nWhat genre consistently has the most “successes”? What genre used to reliably produced “successes” and has fallen out of favor?\n\nAs previously shown, Drama is the leading genre with 53,390 success over the success_threshold.\n\n\nCode\n# Find the genre with the most successes across all decades\ntotal_success_by_genre &lt;- success_by_genre_decade |&gt;\n    group_by(genres) |&gt;\n    summarize(total_success_count = sum(success_count)) |&gt;\n    arrange(desc(total_success_count)) |&gt;\n    slice(1)\n\ntotal_success_by_genre\n\n\n\n\nCode\n# Analyze the trends by comparing the success count in earlier vs recent decades\n# Split into early (before 2000) and recent (2000 and after) decades\nearly_genre_success &lt;- success_by_genre_decade |&gt;\n    filter(decade &lt; 2000) |&gt;\n    group_by(genres) |&gt;\n    summarize(early_success_count = sum(success_count))\n\nrecent_genre_success &lt;- success_by_genre_decade |&gt;\n    filter(decade &gt;= 2000) |&gt;\n    group_by(genres) |&gt;\n    summarize(recent_success_count = sum(success_count))\n\n# Combine the early and recent success counts to compare\ngenre_success_trend &lt;- early_genre_success |&gt;\n    inner_join(recent_genre_success, by = \"genres\", suffix = c(\"_early\", \"_recent\")) |&gt;\n    mutate(success_drop = early_success_count - recent_success_count) |&gt;\n    filter(genres != \"\\\\N\" & !is.na(genres)) |&gt;\n    arrange(desc(success_drop)) |&gt;\n    slice(1)\n\nprint(genre_success_trend)\n\n\nThe data reveals a noticeable decline in the number of successful Western films over time, with a drop of 134 films from the earlier period to the more recent one. This suggests a decreasing popularity or a shift in audience preferences away from the Western genre in recent years\n\nWhat genre has produced the most “successes” since 2010? Does it have the highest success rate or does it only have a large number of successes because there are many productions in that genre?\n\n\n\nCode\n# Filter for movies released since 2010\nsuccess_since_2010 &lt;- success_by_genre_decade |&gt;\n    filter(decade &gt;= 2010) |&gt;\n    group_by(genres) |&gt;\n    summarize(success_count = sum(success_count), .groups = 'drop')\n\n# Count total productions in each genre since 2010\ntotal_productions_since_2010 &lt;- movies_with_genres |&gt;\n    filter(startYear &gt;= 2010) |&gt;\n    separate_rows(genres, sep = \",\") |&gt;\n    group_by(genres) |&gt;\n    summarize(total_productions = n(), .groups = 'drop')\n\n# Combine the success counts with total productions to calculate the success rate\ngenre_success_rate &lt;- success_since_2010 |&gt;\n    inner_join(total_productions_since_2010, by = \"genres\") |&gt;\n    mutate(success_rate = success_count / total_productions) |&gt;\n    filter(success_count &gt;= 5000, genres != \"\\\\N\" & !is.na(genres)) |&gt;\n    arrange(desc(success_count))\n\n# View the genres with their success counts and success rates\nprint(genre_success_rate)\n\n\nSince 2010, Drama has the most successful productions primarily due to its large number of total productions. While its success rate of 33.9% is fairly strong, it is not the highest compared to other genres like Adventure and Action, which both have success rates around 40%. This indicates that Drama’s high number of successes is largely due to the volume of productions in the genre, rather than each individual production having the highest probability of success.\nThus, Drama benefits from sheer volume, while genres like Action and Adventure, though producing fewer total successes, have a higher likelihood of success relative to the number of productions in that genre.\n\nWhat genre has become more popular in recent years?\n\n\n\nCode\n# Compare success counts between earlier decades and 2010s\ngrowth_in_genre &lt;- success_by_genre_decade |&gt;\n    filter(genres != \"\\\\N\" & !is.na(genres), decade %in% c(1990, 2000, 2010)) |&gt;\n    spread(decade, success_count, fill = 0) |&gt;\n    mutate(growth = `2010` - `1990`) |&gt;\n    arrange(desc(growth))\n\ngrowth_in_genre_long &lt;- success_by_genre_decade |&gt;\n  filter(genres != \"\\\\N\" & !is.na(genres), decade %in% c(1990, 2000, 2010)) |&gt;\n  arrange(desc(success_count))\n\n# Create the animated bar chart\np &lt;- ggplot(growth_in_genre_long, aes(x = reorder(genres, success_count), y = success_count, fill = genres)) +\n  geom_bar(stat = \"identity\", show.legend = FALSE) +\n  geom_text(aes(label = scales::comma(round(success_count, 0))),  # Add labels without decimals\n            hjust = -0.2, size = 4) +  # Adjust position and size of labels\n  coord_flip() +\n  labs(title = \"Growth in Genre Success (2010s vs 1990s): {closest_state}\",\n       x = \"Genres\",\n       y = \"Growth\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 0, hjust = 1)) +  # Ensure x-axis labels are horizontal\n  transition_states(decade, transition_length = 2, state_length = 1) +\n  ease_aes('linear') +\n  ylim(0, 30000)\n\n# Animate the plot\nanimate(p, nframes = 100, fps = 10)\n\n\n\n\n\n\n\n\n\nDrama has become the most popular genre in recent years, with a significant growth of successful productions from 1990 to 2010. This is followed by Comedy, Action, Crime, and Adventure, all of which also experienced significant growth in success over this period. These genres have consistently attracted larger audiences and produced more successful movies over the past few decades, showing a trend of increasing popularity."
  },
  {
    "objectID": "mp02.html#successful-personnel-in-the-genre",
    "href": "mp02.html#successful-personnel-in-the-genre",
    "title": "Mini-Project #02: The Business of Show Business",
    "section": "",
    "text": "Code\n# Filter for action movies that are successful\nsuccessful_action_movies &lt;- TITLE_BASICS |&gt;\n    filter(str_detect(genres, \"Action\")) |&gt;  # Only action genre\n    inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n    filter(SuccessScore &gt; success_threshold)  # Use success threshold from earlier\n\n# Find the actors in these successful movies\nsuccessful_actors &lt;- TITLE_PRINCIPALS |&gt;\n    filter(tconst %in% successful_action_movies$tconst) |&gt;\n    inner_join(NAME_BASICS, by = \"nconst\") |&gt;  # Get actor names\n    filter(category == \"actor\") |&gt;  # Filter for actors\n    group_by(primaryName) |&gt;\n    summarize(success_count = n()) |&gt;\n    arrange(desc(success_count)) |&gt;  # Sort by success count\n    head(10)  # Limit to top 10 actors\n\n# Find the directors in these successful movies\n# Split the 'directors' column in TITLE_CREW to separate individual director nconsts\nlibrary(tidyr)\n\nsuccessful_directors &lt;- TITLE_CREW |&gt;\n    filter(tconst %in% successful_action_movies$tconst) |&gt;  # Only action genre movies\n    separate_rows(directors, sep = \",\") |&gt;  # Split the directors column by commas\n    inner_join(NAME_BASICS, by = c(\"directors\" = \"nconst\")) |&gt;  # Join with NAME_BASICS\n    group_by(primaryName) |&gt;  # Group by director name\n    summarize(success_count = n()) |&gt;  # Count successful movies\n    arrange(desc(success_count)) |&gt;  # Sort by success count\n    head(10)  # Limit to top 5 directors\n\n\n\n\nCode\npd &lt;- ggplot(successful_directors, aes(x = reorder(primaryName, success_count), y = success_count, color = primaryName)) +\n  geom_point(size = 5, alpha = 0.7) +\n  labs(title = \"Top Successful Directors in Action Movies: {closest_state}\",\n       x = \"Directors\",\n       y = \"Success Count\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),  # Tilt x-axis labels for readability\n        legend.position = \"none\")\n\n# Add animation\np_directors_anim &lt;- pd +\n  transition_states(primaryName, transition_length = 2, state_length = 1) +\n  shadow_mark() +\n  ease_aes('linear')\n\n# Animate the scatter plot\nanimate(p_directors_anim, nframes = 100, fps = 10)\n\n\n\n\n\n\n\n\n\n\n\nCode\npa &lt;- ggplot(successful_actors, aes(x = reorder(primaryName, success_count), y = success_count, color = primaryName)) +\n  geom_point(size = 5, alpha = 0.7) +\n  labs(title = \"Top Successful Actors in Action Movies: {closest_state}\",\n       x = \"Actors\",\n       y = \"Success Count\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),  # Tilt x-axis labels\n        legend.position = \"none\")\n\n# Add animation\np_actors_anim &lt;- pa +\n  transition_states(primaryName, transition_length = 2, state_length = 1) +\n  shadow_mark() +\n  ease_aes('linear')\n\n# Animate the scatter plot\nanimate(p_actors_anim, nframes = 100, fps = 10)\n\n\n\n\n\n\n\n\n\nBased on these insights, Action/Adventure was selected as the genre for the proposed movie.\nKey Personnel For the project, the following key personnel were selected:\n\nTom Cruise (Director): Cruise, known for his success both as an actor and producer, has a proven track record in the Action genre, with blockbusters like Top Gun: Maverick (2022) and Mission: Impossible series.\nChris Hemsworth (Actor): Hemsworth, famous for his role in Thor and the Avengers series, brings strong action credentials and fan appeal.\nZendaya (Actor): As an up-and-coming talent, Zendaya’s performances in Dune and Spider-Man: No Way Home showcase her versatility and rising star power."
  },
  {
    "objectID": "mp03.html",
    "href": "mp03.html",
    "title": "Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "",
    "text": "Author: Timbila Nikiema\n\n\nThe U.S. Electoral College system has long been a focal point of debate in American politics, with arguments that its structure may skew election results away from the popular vote. In Mini-Project #03, we dive into this discussion by investigating whether a proportional allocation of Electoral College votes could create a more representative presidential election outcome.\nThis project involves examining the existing Electoral College system, integrating data from various government and academic sources, and utilizing spatial data techniques to visualize and analyze election results. By exploring both historical and hypothetical election outcomes under different allocation methods, we aim to assess the representativeness of the presidency and consider how proportional allocation might alter the results.\nThroughout this project, we will:\n\nIntegrate data from disparate sources and learn to work with spatial data formats.\nCreate numerous visualizations, including spatial and animated graphs, to effectively illustrate our findings.\nInvestigate both historical patterns and hypothetical scenarios to understand the potential impact of proportional Electoral College allocations.\n\nThe goal is not to produce a “correct” answer but to foster a thoughtful, data-driven exploration of Electoral College dynamics. We encourage respectful dialogue and constructive feedback during peer reviews, focusing on the quality of analysis, code, visualizations, and argumentation rather than on any political stance.\n\n\n\nFor our analysis, we will be using R, leveraging its powerful data manipulation and visualization capabilities. To ensure we have all the necessary tools, we will load the following libraries:\n\n\nCode\nlibrary(tidyverse)    # For data manipulation and visualization\nlibrary(gganimate)    # For creating plot animation\nlibrary(stringr)      # For string operations\nlibrary(ggplot2)      # For creating static visualizations\nlibrary(gifski)       # For animated visualizations\nlibrary(dplyr)        # For data wrangling\nlibrary(tidyr)        # For tidying data\nlibrary(RCurl)        # For downloading data from URLs\nlibrary(httr)         # For HTTP requests\nlibrary(zip)          # For handling zip files\nlibrary(sf)           # For spatial data manipulation\nlibrary(DT)           # For interactive data tables\n\n\nData I: US House and Presidential Election Votes from 1976 to 2022\nWe will begin our data setup by downloading two key datasets provided by the MIT Election Data Science Lab:[^1]: MIT Election Data + Science Lab. (n.d.). MIT Election Lab. MIT Election Data + Science Lab. https://electionlab.mit.edu/\n\nThe 1976–2022 U.S. House Elections dataset, which includes vote counts for US House elections across this period.\nThe 1976-2020 US Presidential Elections dataset, covering presidential vote counts. These files can be accessed and downloaded directly through the provided links.\n\n\n\nCode\n# Statewide House vote counts\nif(!file.exists(\"1976-2022-house.csv\")){\n       download.file(\"https://dataverse.harvard.edu/file.xhtml?fileId=8963860&version=13.0\", \n                  destfile=\"1976-2022-house.csv\", \n                  quiet=FALSE, \n                  method=\"wget\")}\nHOUSE_DATA &lt;- readr::read_csv(\"1976-2022-house.csv\")\n\n# Statewide Presidential vote counts\nif(!file.exists(\"1976-2020-president.csv\")){\n       download.file(\"https://dataverse.harvard.edu/file.xhtml?fileId=10244938&version=8.0\", \n                  destfile=\"1976-2020-president.csv\", \n                  quiet=FALSE, \n                  method=\"wget\")}\nPRESIDENT_DATA &lt;- readr::read_csv(\"1976-2020-president.csv\")\n\n\nData II: Congressional Boundary Files 1976 to 2012\nThe second key dataset we will need for our analysis includes Congressional Boundary shapefiles. These files provide spatial data for all U.S. congressional districts and are essential for visualizing and analyzing electoral data by district.\n\nCongressional Boundaries (1789–2012): These shapefiles are available from Jeffrey B. Lewis, Brandon DeVine, Lincoln Pritcher, and Kenneth C. Martis and cover all U.S. congressional districts from 1789 to 2012. They can be downloaded from UCLA’s Congressional Districts project.\n\n\n\nCode\n# Task 1: congress shapefiles\n\n# Import congressional district data from 1976 to 2012\nget_cdmaps_file &lt;- function(fname) {\n  BASE_URL &lt;- \"https://cdmaps.polisci.ucla.edu/shp/\"\n  fname_ext &lt;- paste0(fname, \".zip\")\n  if (!file.exists(fname_ext)) {\n    FILE_URL &lt;- paste0(BASE_URL, fname_ext)\n    download.file(FILE_URL,\n                  destfile = fname_ext)}}\n\n# download shape files for 94th to 112th congress\nget_cdmaps_file(\"districts112\")\nget_cdmaps_file(\"districts111\")\nget_cdmaps_file(\"districts110\")\nget_cdmaps_file(\"districts109\")\nget_cdmaps_file(\"districts108\")\nget_cdmaps_file(\"districts107\")\nget_cdmaps_file(\"districts106\")\nget_cdmaps_file(\"districts105\")\nget_cdmaps_file(\"districts104\")\nget_cdmaps_file(\"districts103\")\nget_cdmaps_file(\"districts102\")\nget_cdmaps_file(\"districts101\")\nget_cdmaps_file(\"districts100\")\nget_cdmaps_file(\"districts099\")\nget_cdmaps_file(\"districts098\")\nget_cdmaps_file(\"districts097\")\nget_cdmaps_file(\"districts096\")\nget_cdmaps_file(\"districts095\")\nget_cdmaps_file(\"districts094\")\n\n\n\nCongressional Boundaries (2014–present): For more recent boundaries, we will use the shapefiles provided by the U.S. Census Bureau, which include congressional districts from 2014 to the present. These can be accessed at the U.S. Census Bureau’s TIGER/Line files site.\n\n\n\nCode\n# Task 2\n\n# Import data from US Census 113th to 116th\n\nif (!file.exists(\"districts113.zip\")) {download.file(\"https://www2.census.gov/geo/tiger/TIGER2013/CD/tl_2013_us_cd113.zip\", destfile = \"districts113.zip\")}\n\nif (!file.exists(\"districts114.zip\")) {download.file(\"https://www2.census.gov/geo/tiger/TIGER2014/CD/tl_2014_us_cd114.zip\", destfile = \"districts114.zip\")}\n\nif (!file.exists(\"districts115.zip\")) {download.file(\"https://www2.census.gov/geo/tiger/TIGER2016/CD/tl_2016_us_cd115.zip\", destfile = \"districts115.zip\")}\n\nif (!file.exists(\"districts116.zip\")) {download.file(\"https://www2.census.gov/geo/tiger/TIGER2018/CD/tl_2018_us_cd116.zip\", destfile = \"districts116.zip\")}\n\nif (!file.exists(\"tl_2020_us_state.zip\")) {download.file(\"https://www2.census.gov/geo/tiger/TIGER2020/STATE/tl_2020_us_state.zip\", destfile = \"us_states_shapes.zip\")}\n\n\nThese spatial datasets are crucial for accurate mapping and analysis of congressional district boundaries over time.\n\n\n\nIn this section, we explore the vote count data from the MIT Election Data Science Lab to answer several key questions about electoral trends in the US. This includes analyzing changes in House seats, the impact of New York’s “fusion” voting system, and comparing presidential and congressional vote patterns.\n\nWhich states have gained and lost the most seats in the US House of Representatives between 1976 and 2022?\n\n\n\nCode\n# Find the number of seats in 1976 and 2022 for each state\nseat_count &lt;- HOUSE_DATA |&gt;\n  filter(year %in% c(1976, 2022)) |&gt;\n  group_by(year, state) |&gt;\n  summarise(total_seats = n_distinct(district)) |&gt;\n  select(year, state, total_seats)\n\nseats_1976 &lt;- seat_count |&gt;\n  filter(year == 1976) |&gt;\n  select(state, seats_1976 = total_seats)\n\nseats_2022 &lt;- seat_count |&gt;\n  filter(year == 2022) |&gt;\n  select(state, seats_2022 = total_seats)\n\n# Find the change in seats from 1976 to 2022\nseat_change &lt;- seats_1976 |&gt;\n  inner_join(seats_2022, by = \"state\") |&gt;\n  mutate(seat_change = seats_2022 - seats_1976) |&gt;\n  filter(seat_change != 0)|&gt; # Drop states with no change in seats\n  select(-year.y) |&gt;  # Drop the second \"year\" column by using -year.y\n  arrange(desc(seat_change))\n\n# Visual representation: Graph 1\nggplot(seat_change, aes(x = reorder(state, seat_change), y = seat_change, fill = seat_change &gt; 0)) +\n  geom_bar(stat = \"identity\", show.legend = FALSE) +\n  labs(title = \"Graph 1: Change in US House Seats by State (1976-2022)\",\n       x = \"States\",\n       y = \"Seats Change\") +\n  scale_fill_manual(values = c(\"red\", \"blue\"), labels = c(\"Lost Seats\", \"Gained Seats\")) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Display data table for seat change\ndatatable(setNames(seat_change, c(\"Year\", \"State\", \"Seats 1976\", \"Seats  2022\", \"Seat Change\")),\n          options = list(pageLength = 10, autoWidth = TRUE),\n          caption = \"Table 1: Change in seats in the US House of Representatives between 1976 and 2022\")\n\n\n\n\n\n\nThis analysis highlights the states that saw increases or decreases in their House representation over this period. States with significant population growth, such as Texas and Florida, gained over 27 seats collectively, reflecting substantial increases in representation. Conversely, states with slower growth or population decline saw reductions in their House seats, indicating regional demographic shifts impacting representation.\n\nAre there any elections in our data where the election would have had a different outcome if the “fusion” system was not used and candidates only received the votes their received from their “major party line” (Democrat or Republican) and not their total number of votes across all lines?\n\n\n\nCode\n# clean up: exclude \"writein\" candidates, \"blank\" candidates, and NA in party field\nelection &lt;- HOUSE_DATA |&gt;\n  filter(!grepl(\"blank\", candidate, ignore.case = TRUE), # Exclude candidates with \"blank\" in their name\n         candidate != \"writein\", # Exclude rows with candidate listed as \"writein\"\n         !is.na(party)) # Exclude rows where party is NA\n\n# Identify fusion candidates: those with more than one party in the same election\nfusion_candidates &lt;- election |&gt;\n  group_by(year, state, state_po, candidate) |&gt;\n  summarise(\n    total_votes = sum(candidatevotes), # total votes across all lines\n    party_votes = sum(candidatevotes[party %in% c(\"DEMOCRAT\", \"REPUBLICAN\")]),\n    .groups = \"drop\" # remove grouping after summarizing\n  ) |&gt;\n  filter(n() &gt; 1) # Only keep candidates with multiple party lines\n\n# Determine if excluding fusion votes changes the outcome\noutcome_change &lt;- fusion_candidates |&gt;\n  group_by(year, state, state_po) |&gt;\n  mutate(\n    winner_with_fusion = candidate[which.max(total_votes)],\n    winner_without_fusion = candidate[which.max(party_votes)],\n    outcome_changed = winner_with_fusion != winner_without_fusion\n  ) |&gt;\n  ungroup() # ungroup after mutate for clean output\n\n# Display elections where outcome changes without the fusion voting\nresult_table &lt;- outcome_change |&gt;\n  filter(outcome_changed) |&gt;\n  select(year, state, state_po, winner_with_fusion, winner_without_fusion, outcome_changed) |&gt;\n  distinct()\n\n# Format the table to display 10 rows with the caption at the bottom\ndatatable(result_table,\n          options = list(pageLength = 10, autoWidth = TRUE, captionSide = \"bottom\"),\n          caption = \"Table 2: Election Fusion Winners (Excluding Write-in, Blank Candidates, and NA in Party Field)\") |&gt;\n  formatStyle(columns = names(result_table), fontSize = '100%')\n\n\n\n\n\n\nThis table shows the historical elections for which the outcome would have been different had not been for the fusion voting system.\n\nDo presidential candidates tend to run ahead of or run behind congressional candidates in the same state? That is, does a Democratic candidate for president tend to get more votes in a given state than all Democratic congressional candidates in the same state?\n\nDoes this trend differ over time? Does it differ across states or across parties? Are any presidents particularly more or less popular than their co-partisans?\n\n\nCode\n# Aggregate Congressional votes\ncongress_votes &lt;- HOUSE_DATA |&gt;\n   group_by(year, state, party) |&gt;\n  summarise(congress_votes = sum(candidatevotes), .groups = \"drop\")\n\n# Aggregate Presidential votes\npresident_votes &lt;- PRESIDENT_DATA |&gt;\n  group_by(year, state, party_detailed) |&gt;\n  summarise(president_votes = sum(candidatevotes), .groups = \"drop\") |&gt;\n  rename(\"party\" = \"party_detailed\")\n\n# Congress and Presidential data merged and vote difference calculation\nvote_difference &lt;- congress_votes |&gt;\n  inner_join(president_votes, by = c(\"year\", \"state\", \"party\")) |&gt;\n  mutate(vote_difference = president_votes - congress_votes) |&gt;\n  select(-president_votes, -congress_votes)\n  \n# Democrat and Republican vote data\nselected_parties &lt;- vote_difference |&gt;\n  filter(party %in% c(\"DEMOCRAT\", \"REPUBLICAN\")) |&gt;\n  group_by(year, party) |&gt;\n  summarise(avg_vote_diff = mean(vote_difference))\n\n# Display the results in a datatable\ntabledata &lt;- vote_difference |&gt;\n  filter(party %in% c(\"DEMOCRAT\", \"REPUBLICAN\")) |&gt;\n  select(state, party,vote_difference)\n\ndatatable(setNames(tabledata, c(\"State\", \"Party\", \"Vote Difference\")),\n          options = list(pageLength = 10, autoWidth = TRUE),\n          caption = \"Table 3: Presidential Votes vs Congress Votes\") |&gt;\n  formatRound(columns = \"Vote Difference\", digits = 0)\n\n\n\n\n\n\n\n\nCode\n# Plot average vote difference by year and party\nggplot(selected_parties, aes(x = year, y = avg_vote_diff, color = party)) +\n  geom_line() +\n  scale_color_manual(values = c(\"DEMOCRAT\" = \"blue\", \"REPUBLICAN\" = \"red\")) +\n  labs(title = \"Graph 2: Vote Difference (Presidential - Congressional) by Party Over Time\",\n       x = \"Year\", y = \"Average Vote Difference\") +\n  theme_minimal() |&gt;\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\nThe table and graph above show the vote difference between presidential and congressional candidates across various states, broken down by party. Presidential candidates’ performance does not always align with their party’s performance in congressional races. In some cases, the presidential candidates outperform their congressional counterparts, while in others, it’s the reverse. The vote differences can vary significantly across states and parties, indicating that voter preferences for presidential and congressional candidates can be quite different.\n\n\n\nFrom the district file downloaded earlier, we will need to read and extract the shape files for further analysis of the 2000 presidential elections.\n\n\nCode\nzip_file &lt;- \"districts106.zip\"\n\n# Extract the contents of the zip files\nunzip(zip_file)\n\n# Read the 106th district shape file\nshapefile_106 &lt;- st_read(file.path(\"districtShapes/districts106.shp\"))\n\n\nReading layer `districts106' from data source \n  `C:\\Users\\Timbila Nikiema\\OneDrive\\Documents\\STA9750-2024-FALL\\districtShapes\\districts106.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 436 features and 15 fields (with 1 geometry empty)\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -179.1473 ymin: 18.9177 xmax: 179.7785 ymax: 71.35256\nGeodetic CRS:  GRS 1980(IUGG, 1980)\n\n\nThe following R code creates a choropleth map visualizing the 2000 U.S. presidential election results by state. Using election data joined with U.S. state geometries, the map displays each state colored by the winning party (Republican or Democratic). Insets for Alaska and Hawaii are added for clarity, and each state is labeled with its two-letter postal abbreviation for easier identification. This visualization provides a clear, geographic perspective of the electoral outcomes across the contiguous United States, with separate, scaled-down views of Alaska and Hawaii.\n\n\nCode\n# Task 5: Chloropleth Visualization of the 2000 Presidential Election Electoral College Results\n\n# 2000 elections data\nelections_2000 &lt;- PRESIDENT_DATA |&gt;\n  filter(year == 2000) |&gt;\n  group_by(state, party_simplified) |&gt;\n  summarize(total_votes = sum(candidatevotes), .groups = \"drop\") |&gt;\n  group_by(state) |&gt;\n  slice_max(total_votes, n = 1) |&gt;\n  ungroup() |&gt;\n  select(state, party_simplified) |&gt;\n  rename(Party = party_simplified)\n\n# join the shape file to election results\nshapefile_us_2000 &lt;- shapefile_106 |&gt;\n  mutate(STATENAME = toupper(trimws(STATENAME))) |&gt; \n  left_join(elections_2000, join_by(STATENAME == state))\n\n# create Choropleth of contiguous US first\nconsolidated_map &lt;- ggplot(shapefile_us_2000, aes(geometry = geometry, fill = Party), color = \"black\") +\n  geom_sf() +\n  scale_fill_manual(values = c(\"DEMOCRAT\" = \"skyblue3\", \"REPUBLICAN\" = \"firebrick1\")) +\n  theme_minimal() +\n  labs(title = \"Graph 3: 2000 Presidential Election Results by State\", fill = \"Party\") +\n  theme(legend.position = \"bottom\") +\n  coord_sf(xlim = c(-130, -60), ylim = c(20, 50), expand = FALSE)\n\n# Alaska inset\nalaska_sf &lt;- shapefile_us_2000[shapefile_us_2000$STATENAME == \"ALASKA\", ]\ninset_alaska &lt;- ggplot(alaska_sf,\n  aes(geometry = geometry, fill = Party), color = \"black\") +\n  geom_sf() +\n  scale_fill_manual(values = c(\"DEMOCRAT\" = \"skyblue3\", \"REPUBLICAN\" = \"firebrick1\")) +\n  theme_void() +\n  theme(legend.position = \"none\") +\n  coord_sf(xlim = c(-180, -140), ylim = c(50, 72), expand = FALSE)\n\n# Hawaii inset\nhawaii_sf &lt;- shapefile_us_2000[shapefile_us_2000$STATENAME == \"HAWAII\", ]\ninset_hawaii &lt;- ggplot(hawaii_sf, aes(geometry = geometry, fill = Party), color = \"black\") +\n  geom_sf() +\n  scale_fill_manual(values = c(\"DEMOCRAT\" = \"skyblue3\", \"REPUBLICAN\" = \"firebrick1\")) +\n  theme_void() +\n  theme(legend.position = \"none\") +\n  coord_sf(xlim = c(-161, -154), ylim = c(20, 22), expand = FALSE)\n\ncombined_map &lt;- consolidated_map +\n  annotation_custom(ggplotGrob(inset_alaska),\n    xmin = -120, xmax = -130, # Adjust position for Alaska\n    ymin = 15, ymax = 40) +\n  annotation_custom(ggplotGrob(inset_hawaii),\n    xmin = -115, xmax = -100, # Adjust position for Hawaii\n    ymin = 20, ymax = 30) # Adjust these values to fit\n\n# Print the combined map\nprint(combined_map)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Task 6: Advanced Chloropleth Visualization of Electoral College Results\n\n# Modify your previous code to make an animated version showing election results over time.\n\n# List of election years\nelection_years &lt;- c(1976, 1980, 1984, 1988, 1992, 1996, 2000, 2004, 2008, 2012, 2016, 2020)\n\n# Function to process election results for a specific year\nwinner_by_year &lt;- function(input_year) {\n  PRESIDENT_DATA |&gt;\n    filter(year == input_year) |&gt; # Filter for the specific year\n    group_by(state, party_simplified) |&gt;\n    summarize(total_votes = sum(candidatevotes), .groups = \"drop\") |&gt;\n    group_by(state) |&gt;\n    slice_max(total_votes, n = 1) |&gt;\n    ungroup() |&gt;\n    select(state, party_simplified) |&gt;\n    rename(winning_party = party_simplified) |&gt;\n    mutate(year = input_year) # Add year to the table\n}\n\n# Combine each year's results into one data table\nelection_results &lt;- bind_rows(lapply(election_years, winner_by_year))\n\n# Load the state shape files\nstates_shapes &lt;- st_read(\"tl_2020_us_state.shp\") |&gt;\n  mutate(STATE = toupper(trimws(NAME)))\n\n\nReading layer `tl_2020_us_state' from data source \n  `C:\\Users\\Timbila Nikiema\\OneDrive\\Documents\\STA9750-2024-FALL\\tl_2020_us_state.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 56 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -179.2311 ymin: -14.60181 xmax: 179.8597 ymax: 71.43979\nGeodetic CRS:  NAD83\n\n\nCode\n# Exclude Alaska and Hawaii\nstates_shapes &lt;- states_shapes |&gt; \n  filter(!STATE %in% c(\"ALASKA\", \"HAWAII\"))\n\n# Join the election data with the shapefile for all years\nelection_results &lt;- states_shapes |&gt;\n  left_join(election_results |&gt; mutate(state = toupper(trimws(state))), \n            by = c(\"STATE\" = \"state\")) |&gt; \n  filter(!is.na(year)) # Excluding any NAs\n\n# Create the animated plot\nanimate_election_results &lt;- ggplot(election_results, aes(geometry = geometry, fill = winning_party), color = \"black\") +\n  geom_sf() +\n  scale_fill_manual(values = c(\"DEMOCRAT\" = \"skyblue3\", \"REPUBLICAN\" = \"firebrick1\")) +\n  theme_minimal() +\n  labs(title = \"Graph 4: Presidential Election State Results {closest_state}\", fill = \"Winning Party\") +\n  theme(legend.position = \"bottom\") +\n  transition_states(year, transition_length = 0, state_length = 1) +\n  coord_sf(xlim = c(-125, -65), ylim = c(25, 50), expand = FALSE) # Exclude Alaska and Hawaii\n\n# Print the animated graph\nanimate(animate_election_results, fps = 10)\n\n\n\n\n\n\n\n\n\n\n\n\nTo evaluate the fairness and effects of different Electoral College Vote (ECV) allocation schemes, we’ll walk through a series of steps for each allocation mentioned strategies. The analysis will include comparing each allocation scheme’s results against the historical winners to uncover any systematic biases, and then assessing which scheme is “fairest” in terms of how it impacts election outcomes.\n\n\nThe candidate with the most votes in the state wins all the state’s electoral votes.\n\n\nCode\n# Electoral college count\nelectoral_count &lt;- HOUSE_DATA |&gt;\n  group_by(year, state) |&gt;\n  summarise(reps_count = n_distinct(district)) |&gt;\n  mutate(electoral_votes = reps_count + 2) |&gt; \n  select(year, state, electoral_votes)\n\n# find the candidate with the most votes each year in each state\nstate_wide_winner_take_all &lt;- PRESIDENT_DATA |&gt;\n  group_by(year, state, candidate) |&gt;\n  summarize(total_votes = sum(candidatevotes), .groups = \"drop\") |&gt;\n  group_by(year, state) |&gt;\n  slice_max(order_by = total_votes, n = 1, with_ties = FALSE) |&gt; # find the winner of each state based on total votes\n  rename(winner = candidate) # rename for conventional understanding\n\n# join the state, winner, and number of electoral votes & sum which candidate that gets the most electoral votes\nstate_wide_winner_take_all &lt;- state_wide_winner_take_all |&gt;\n  left_join(electoral_count,\n    by = c(\"year\", \"state\")) |&gt;\n  group_by(year, winner) |&gt;\n  summarize(total_electoral_votes = sum(electoral_votes)) |&gt; # sum electoral votes across all states by candidate each year\n  slice_max(order_by = total_electoral_votes, n = 1, with_ties = FALSE)\n\n\n\n\nCode\ndatatable(setNames(state_wide_winner_take_all, c(\"Year\", \"Winning Candidate\", \"Electoral Votes\")),\n          options = list(pageLength = 12, autoWidth = TRUE),\n          caption = \"Table 4: State-Wide Winner-Take-All: Presidential Winning Candidate\")\n\n\n\n\n\n\nThe WTA method tends to exaggerate the margin of victory for the winning candidate, disproportionately amplifying the impact of swing states. It can produce outcomes that diverge significantly from the national popular vote. For example: * 2000 Election: George W. Bush won the presidency with 271 ECVs to Al Gore’s 266, despite losing the popular vote. * 2016 Election: Donald Trump won the presidency with 305 ECVs to Hillary Clinton’s 227, again losing the popular vote.\n\n\n\nStates like Maine and Nebraska use this system, where electors are assigned both based on the winners of each congressional district (district-level WTA) and a set of electors awarded to the winner of the statewide vote. This is a hybrid of district-level and state-wide allocation.\n\n\nCode\n# find number of districts each party won to represent electoral votes won in each state\ndistrict_winner &lt;- HOUSE_DATA |&gt;\n  group_by(year, state, district) |&gt;\n  slice_max(order_by = candidatevotes, n = 1, with_ties = FALSE) |&gt;\n  select(year, state, district, party) |&gt;\n  group_by(year, state, party) |&gt;\n  summarize(districts_won = n()) # number of electoral votes received by each party\n\n# find popular vote winner in the state\nat_large_winner &lt;- HOUSE_DATA |&gt;\n  group_by(year, state) |&gt;\n  slice_max(order_by = candidatevotes, n = 1, with_ties = FALSE) |&gt;\n  select(year, state, party) |&gt;\n  add_column(at_large_votes = 2) # designating the vote count\n\n# join tables together to find total electoral votes the presidential party receives in each state\ndistrict_wide_winner_take_all &lt;- district_winner |&gt;\n  left_join(at_large_winner, by = c(\"year\", \"state\", \"party\")) |&gt;\n  mutate(across(where(is.numeric), ~ ifelse(is.na(.), 0, .))) |&gt; \n  mutate(total_electoral_votes = districts_won + at_large_votes) |&gt;\n  select(-districts_won, -at_large_votes) |&gt;\n  rename(party_simplified = party) |&gt; # rename for easier joining convention\n  left_join(PRESIDENT_DATA, by = c(\"year\", \"state\", \"party_simplified\")) |&gt; # join to presidential candidate\n  select(year, state, total_electoral_votes, candidate) |&gt;\n  group_by(year, candidate) |&gt;\n  summarize(electoral_votes = sum(total_electoral_votes)) |&gt;\n  slice_max(order_by = electoral_votes, n = 1, with_ties = FALSE) |&gt;\n  drop_na() # get rid of the non-presidential election years\n\n\n\n\nCode\ndatatable(setNames(district_wide_winner_take_all, c(\"Year\", \"Winning Candidate\", \"Electoral Votes\")),\n          options = list(pageLength = 12, autoWidth = TRUE),\n          caption = \"Table 5: District-Wide Winner-Take-All: Presidential Winning Candidate\")\n\n\n\n\n\n\nThis scheme introduces more granularity but can still deviate significantly from the popular vote due to district-level gerrymandering. In elections like 2012, Barack Obama won both Maine’s districts and the state, earning all its ECVs. In 2020, Nebraska awarded some ECVs to Joe Biden while awarding most to Donald Trump.\n\n\n\nThe state’s electoral votes are distributed proportionally based on the percentage of the popular vote each candidate receives. For example, if a candidate wins 40% of the vote in a state with 10 ECVs, they get 4 ECVs.\n\n\nCode\n# find the percentage of the votes received in each state\nstate_wide_proportional &lt;- PRESIDENT_DATA |&gt;\n  select(year, state, candidate, candidatevotes, totalvotes) |&gt;\n  mutate(percentage_state_votes = (candidatevotes / totalvotes)) |&gt;\n  select(-candidatevotes, -totalvotes)\n\n# find the number of electoral votes received by each candidate\nstate_wide_proportional &lt;- state_wide_proportional |&gt;\n  inner_join(electoral_count, by = c(\"year\", \"state\")) |&gt;\n  mutate(votes_received = round(percentage_state_votes * electoral_votes, digits = 0)) |&gt;\n  select(-percentage_state_votes, -electoral_votes)\n\n# sum total votes and find presidential winner\nstate_wide_proportional &lt;- state_wide_proportional |&gt;\n  group_by(year, candidate) |&gt;\n  summarize(total_electoral_votes = sum(votes_received)) |&gt;\n  slice_max(order_by = total_electoral_votes, n = 1, with_ties = FALSE) |&gt;\n  rename(winner = candidate)\n\n\n\n\nCode\ndatatable(setNames(state_wide_proportional, c(\"Year\", \"Winning Candidate\", \"Electoral Votes\")),\n          options = list(pageLength = 12, autoWidth = TRUE),\n          caption = \"Table 6: State-Wide Proportional: Presidential Winning Candidate\")\n\n\n\n\n\n\nThis scheme aligns more closely with the popular vote, reducing distortions caused by WTA. However, it may lead to no candidate receiving a majority of ECVs, increasing the likelihood of the election being decided by the House of Representatives.\n\n\n\nElectoral votes are distributed proportionally across the entire nation rather than by state, based on the percentage of the national popular vote each candidate receives. This system eliminates the state-based winner-take-all feature and distributes ECVs based purely on national vote share.\n\n\nCode\n# find total number of electoral votes available\nelectoral_votes_available &lt;- electoral_count |&gt;\n  group_by(year) |&gt;\n  summarize(electoral_college_votes = sum(electoral_votes))\n\n# find percentage of popular vote each candidate received\nnational_proportional &lt;- PRESIDENT_DATA |&gt;\n  select(year, state, candidate, candidatevotes) |&gt;\n  group_by(year, candidate) |&gt;\n  summarize(total_electoral_votes = sum(candidatevotes)) |&gt;\n  group_by(year) |&gt;\n  mutate(population_vote_count = sum(total_electoral_votes)) |&gt; # find total number of votes cast in election year\n  ungroup() |&gt;\n  mutate(percentage_population_vote = (total_electoral_votes / population_vote_count)) |&gt;\n  select(-total_electoral_votes, -population_vote_count) |&gt;\n  \n  # find the allocation of the electoral votes based on the popular vote percentage\n  left_join(electoral_votes_available, join_by(year == year)) |&gt;\n  mutate(electoral_votes_received = round(percentage_population_vote * electoral_college_votes, digits = 0)) |&gt;\n  select(-percentage_population_vote, -electoral_college_votes) |&gt;\n  group_by(year) |&gt;\n  slice_max(order_by = electoral_votes_received, n = 1, with_ties = FALSE) |&gt;\n  rename(winner = candidate)\n\n\n\n\nCode\ndatatable(setNames(national_proportional, c(\"Year\", \"Winning Candidate\", \"Electoral Votes\")),\n          options = list(pageLength = 12, autoWidth = TRUE),\n          caption = \"Table 7: National Proportional: Presidential Winning Candidate\")\n\n\n\n\n\n\n\n\nCode\n# Load the necessary package\nlibrary(knitr)\nlibrary(kableExtra)\n\n# Create the data frame\ncomparison_table &lt;- data.frame(\n  \"Allocation Method\" = c(\n    \"State-Wide Winner-Take-All\", \n    \"District-Based Allocation\", \n    \"Proportional Allocation\"\n  ),\n  \"Popular Vote Alignment\" = c(\"Low\", \"Moderate\", \"High\"),\n  \"Swing State Influence\" = c(\"High\", \"Moderate\", \"Low\"),\n  \"Fairness\" = c(\"Biased\", \"Mixed\", \"Fairest\"),\n  \"Example Outcome\" = c(\n    \"2000: Bush wins despite losing PV\",\n    \"Amplifies gerrymandering effects\",\n    \"2000: Gore wins, aligning with PV\"))\n\n# Generate and format the table with adjustable size\ncomparison_table |&gt; \n  kable(\n    caption = \"Comparison of Allocation Methods:\",\n    col.names = c(\"Allocation Method\", \"Popular Vote Alignment\", \"Swing State Influence\", \"Fairness\", \"Example Outcome\"), align = \"l\") |&gt; \n  kable_styling(\n    full_width = TRUE,     # Make the table use the full width\n    position = \"center\",   # Center-align the table\n    font_size = 14)        # Adjust the font size for better readability\n\n\n\nComparison of Allocation Methods:\n\n\nAllocation Method\nPopular Vote Alignment\nSwing State Influence\nFairness\nExample Outcome\n\n\n\n\nState-Wide Winner-Take-All\nLow\nHigh\nBiased\n2000: Bush wins despite losing PV\n\n\nDistrict-Based Allocation\nModerate\nModerate\nMixed\nAmplifies gerrymandering effects\n\n\nProportional Allocation\nHigh\nLow\nFairest\n2000: Gore wins, aligning with PV\n\n\n\n\n\n\n\n\n\n\n\nAmong the three methods, Proportional Allocation is the fairest in terms of aligning with the popular vote and reducing distortions caused by state size or swing state dynamics. However, its drawback of potentially not producing a decisive winner suggests that reforms should carefully weigh the trade-offs between fairness and administrative simplicity.\nThe Winner-Take-All method is the least fair due to its high distortions, as seen in elections like 2000 and 2016. Meanwhile, District-Based Allocation offers granularity but suffers from gerrymandering issues. Proportional allocation represents the best balance for fairness and voter representation."
  },
  {
    "objectID": "mp03.html#introduction",
    "href": "mp03.html#introduction",
    "title": "Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "",
    "text": "The U.S. Electoral College system has long been a focal point of debate in American politics, with arguments that its structure may skew election results away from the popular vote. In Mini-Project #03, we dive into this discussion by investigating whether a proportional allocation of Electoral College votes could create a more representative presidential election outcome.\nThis project involves examining the existing Electoral College system, integrating data from various government and academic sources, and utilizing spatial data techniques to visualize and analyze election results. By exploring both historical and hypothetical election outcomes under different allocation methods, we aim to assess the representativeness of the presidency and consider how proportional allocation might alter the results.\nThroughout this project, we will:\n\nIntegrate data from disparate sources and learn to work with spatial data formats.\nCreate numerous visualizations, including spatial and animated graphs, to effectively illustrate our findings.\nInvestigate both historical patterns and hypothetical scenarios to understand the potential impact of proportional Electoral College allocations.\n\nThe goal is not to produce a “correct” answer but to foster a thoughtful, data-driven exploration of Electoral College dynamics. We encourage respectful dialogue and constructive feedback during peer reviews, focusing on the quality of analysis, code, visualizations, and argumentation rather than on any political stance."
  },
  {
    "objectID": "mp03.html#data-acquisition",
    "href": "mp03.html#data-acquisition",
    "title": "Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "",
    "text": "For our analysis, we will be using R, leveraging its powerful data manipulation and visualization capabilities. To ensure we have all the necessary tools, we will load the following libraries:\n\n\nCode\nlibrary(tidyverse)    # For data manipulation and visualization\nlibrary(gganimate)    # For creating plot animation\nlibrary(stringr)      # For string operations\nlibrary(ggplot2)      # For creating static visualizations\nlibrary(gifski)       # For animated visualizations\nlibrary(dplyr)        # For data wrangling\nlibrary(tidyr)        # For tidying data\nlibrary(RCurl)        # For downloading data from URLs\nlibrary(httr)         # For HTTP requests\nlibrary(zip)          # For handling zip files\nlibrary(sf)           # For spatial data manipulation\nlibrary(DT)           # For interactive data tables\n\n\nData I: US House and Presidential Election Votes from 1976 to 2022\nWe will begin our data setup by downloading two key datasets provided by the MIT Election Data Science Lab:[^1]: MIT Election Data + Science Lab. (n.d.). MIT Election Lab. MIT Election Data + Science Lab. https://electionlab.mit.edu/\n\nThe 1976–2022 U.S. House Elections dataset, which includes vote counts for US House elections across this period.\nThe 1976-2020 US Presidential Elections dataset, covering presidential vote counts. These files can be accessed and downloaded directly through the provided links.\n\n\n\nCode\n# Statewide House vote counts\nif(!file.exists(\"1976-2022-house.csv\")){\n       download.file(\"https://dataverse.harvard.edu/file.xhtml?fileId=8963860&version=13.0\", \n                  destfile=\"1976-2022-house.csv\", \n                  quiet=FALSE, \n                  method=\"wget\")}\nHOUSE_DATA &lt;- readr::read_csv(\"1976-2022-house.csv\")\n\n# Statewide Presidential vote counts\nif(!file.exists(\"1976-2020-president.csv\")){\n       download.file(\"https://dataverse.harvard.edu/file.xhtml?fileId=10244938&version=8.0\", \n                  destfile=\"1976-2020-president.csv\", \n                  quiet=FALSE, \n                  method=\"wget\")}\nPRESIDENT_DATA &lt;- readr::read_csv(\"1976-2020-president.csv\")\n\n\nData II: Congressional Boundary Files 1976 to 2012\nThe second key dataset we will need for our analysis includes Congressional Boundary shapefiles. These files provide spatial data for all U.S. congressional districts and are essential for visualizing and analyzing electoral data by district.\n\nCongressional Boundaries (1789–2012): These shapefiles are available from Jeffrey B. Lewis, Brandon DeVine, Lincoln Pritcher, and Kenneth C. Martis and cover all U.S. congressional districts from 1789 to 2012. They can be downloaded from UCLA’s Congressional Districts project.\n\n\n\nCode\n# Task 1: congress shapefiles\n\n# Import congressional district data from 1976 to 2012\nget_cdmaps_file &lt;- function(fname) {\n  BASE_URL &lt;- \"https://cdmaps.polisci.ucla.edu/shp/\"\n  fname_ext &lt;- paste0(fname, \".zip\")\n  if (!file.exists(fname_ext)) {\n    FILE_URL &lt;- paste0(BASE_URL, fname_ext)\n    download.file(FILE_URL,\n                  destfile = fname_ext)}}\n\n# download shape files for 94th to 112th congress\nget_cdmaps_file(\"districts112\")\nget_cdmaps_file(\"districts111\")\nget_cdmaps_file(\"districts110\")\nget_cdmaps_file(\"districts109\")\nget_cdmaps_file(\"districts108\")\nget_cdmaps_file(\"districts107\")\nget_cdmaps_file(\"districts106\")\nget_cdmaps_file(\"districts105\")\nget_cdmaps_file(\"districts104\")\nget_cdmaps_file(\"districts103\")\nget_cdmaps_file(\"districts102\")\nget_cdmaps_file(\"districts101\")\nget_cdmaps_file(\"districts100\")\nget_cdmaps_file(\"districts099\")\nget_cdmaps_file(\"districts098\")\nget_cdmaps_file(\"districts097\")\nget_cdmaps_file(\"districts096\")\nget_cdmaps_file(\"districts095\")\nget_cdmaps_file(\"districts094\")\n\n\n\nCongressional Boundaries (2014–present): For more recent boundaries, we will use the shapefiles provided by the U.S. Census Bureau, which include congressional districts from 2014 to the present. These can be accessed at the U.S. Census Bureau’s TIGER/Line files site.\n\n\n\nCode\n# Task 2\n\n# Import data from US Census 113th to 116th\n\nif (!file.exists(\"districts113.zip\")) {download.file(\"https://www2.census.gov/geo/tiger/TIGER2013/CD/tl_2013_us_cd113.zip\", destfile = \"districts113.zip\")}\n\nif (!file.exists(\"districts114.zip\")) {download.file(\"https://www2.census.gov/geo/tiger/TIGER2014/CD/tl_2014_us_cd114.zip\", destfile = \"districts114.zip\")}\n\nif (!file.exists(\"districts115.zip\")) {download.file(\"https://www2.census.gov/geo/tiger/TIGER2016/CD/tl_2016_us_cd115.zip\", destfile = \"districts115.zip\")}\n\nif (!file.exists(\"districts116.zip\")) {download.file(\"https://www2.census.gov/geo/tiger/TIGER2018/CD/tl_2018_us_cd116.zip\", destfile = \"districts116.zip\")}\n\nif (!file.exists(\"tl_2020_us_state.zip\")) {download.file(\"https://www2.census.gov/geo/tiger/TIGER2020/STATE/tl_2020_us_state.zip\", destfile = \"us_states_shapes.zip\")}\n\n\nThese spatial datasets are crucial for accurate mapping and analysis of congressional district boundaries over time."
  },
  {
    "objectID": "mp03.html#initial-exploration-of-vote-count-data",
    "href": "mp03.html#initial-exploration-of-vote-count-data",
    "title": "Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "",
    "text": "In this section, we explore the vote count data from the MIT Election Data Science Lab to answer several key questions about electoral trends in the US. This includes analyzing changes in House seats, the impact of New York’s “fusion” voting system, and comparing presidential and congressional vote patterns.\n\nWhich states have gained and lost the most seats in the US House of Representatives between 1976 and 2022?\n\n\n\nCode\n# Find the number of seats in 1976 and 2022 for each state\nseat_count &lt;- HOUSE_DATA |&gt;\n  filter(year %in% c(1976, 2022)) |&gt;\n  group_by(year, state) |&gt;\n  summarise(total_seats = n_distinct(district)) |&gt;\n  select(year, state, total_seats)\n\nseats_1976 &lt;- seat_count |&gt;\n  filter(year == 1976) |&gt;\n  select(state, seats_1976 = total_seats)\n\nseats_2022 &lt;- seat_count |&gt;\n  filter(year == 2022) |&gt;\n  select(state, seats_2022 = total_seats)\n\n# Find the change in seats from 1976 to 2022\nseat_change &lt;- seats_1976 |&gt;\n  inner_join(seats_2022, by = \"state\") |&gt;\n  mutate(seat_change = seats_2022 - seats_1976) |&gt;\n  filter(seat_change != 0)|&gt; # Drop states with no change in seats\n  select(-year.y) |&gt;  # Drop the second \"year\" column by using -year.y\n  arrange(desc(seat_change))\n\n# Visual representation: Graph 1\nggplot(seat_change, aes(x = reorder(state, seat_change), y = seat_change, fill = seat_change &gt; 0)) +\n  geom_bar(stat = \"identity\", show.legend = FALSE) +\n  labs(title = \"Graph 1: Change in US House Seats by State (1976-2022)\",\n       x = \"States\",\n       y = \"Seats Change\") +\n  scale_fill_manual(values = c(\"red\", \"blue\"), labels = c(\"Lost Seats\", \"Gained Seats\")) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Display data table for seat change\ndatatable(setNames(seat_change, c(\"Year\", \"State\", \"Seats 1976\", \"Seats  2022\", \"Seat Change\")),\n          options = list(pageLength = 10, autoWidth = TRUE),\n          caption = \"Table 1: Change in seats in the US House of Representatives between 1976 and 2022\")\n\n\n\n\n\n\nThis analysis highlights the states that saw increases or decreases in their House representation over this period. States with significant population growth, such as Texas and Florida, gained over 27 seats collectively, reflecting substantial increases in representation. Conversely, states with slower growth or population decline saw reductions in their House seats, indicating regional demographic shifts impacting representation.\n\nAre there any elections in our data where the election would have had a different outcome if the “fusion” system was not used and candidates only received the votes their received from their “major party line” (Democrat or Republican) and not their total number of votes across all lines?\n\n\n\nCode\n# clean up: exclude \"writein\" candidates, \"blank\" candidates, and NA in party field\nelection &lt;- HOUSE_DATA |&gt;\n  filter(!grepl(\"blank\", candidate, ignore.case = TRUE), # Exclude candidates with \"blank\" in their name\n         candidate != \"writein\", # Exclude rows with candidate listed as \"writein\"\n         !is.na(party)) # Exclude rows where party is NA\n\n# Identify fusion candidates: those with more than one party in the same election\nfusion_candidates &lt;- election |&gt;\n  group_by(year, state, state_po, candidate) |&gt;\n  summarise(\n    total_votes = sum(candidatevotes), # total votes across all lines\n    party_votes = sum(candidatevotes[party %in% c(\"DEMOCRAT\", \"REPUBLICAN\")]),\n    .groups = \"drop\" # remove grouping after summarizing\n  ) |&gt;\n  filter(n() &gt; 1) # Only keep candidates with multiple party lines\n\n# Determine if excluding fusion votes changes the outcome\noutcome_change &lt;- fusion_candidates |&gt;\n  group_by(year, state, state_po) |&gt;\n  mutate(\n    winner_with_fusion = candidate[which.max(total_votes)],\n    winner_without_fusion = candidate[which.max(party_votes)],\n    outcome_changed = winner_with_fusion != winner_without_fusion\n  ) |&gt;\n  ungroup() # ungroup after mutate for clean output\n\n# Display elections where outcome changes without the fusion voting\nresult_table &lt;- outcome_change |&gt;\n  filter(outcome_changed) |&gt;\n  select(year, state, state_po, winner_with_fusion, winner_without_fusion, outcome_changed) |&gt;\n  distinct()\n\n# Format the table to display 10 rows with the caption at the bottom\ndatatable(result_table,\n          options = list(pageLength = 10, autoWidth = TRUE, captionSide = \"bottom\"),\n          caption = \"Table 2: Election Fusion Winners (Excluding Write-in, Blank Candidates, and NA in Party Field)\") |&gt;\n  formatStyle(columns = names(result_table), fontSize = '100%')\n\n\n\n\n\n\nThis table shows the historical elections for which the outcome would have been different had not been for the fusion voting system.\n\nDo presidential candidates tend to run ahead of or run behind congressional candidates in the same state? That is, does a Democratic candidate for president tend to get more votes in a given state than all Democratic congressional candidates in the same state?\n\nDoes this trend differ over time? Does it differ across states or across parties? Are any presidents particularly more or less popular than their co-partisans?\n\n\nCode\n# Aggregate Congressional votes\ncongress_votes &lt;- HOUSE_DATA |&gt;\n   group_by(year, state, party) |&gt;\n  summarise(congress_votes = sum(candidatevotes), .groups = \"drop\")\n\n# Aggregate Presidential votes\npresident_votes &lt;- PRESIDENT_DATA |&gt;\n  group_by(year, state, party_detailed) |&gt;\n  summarise(president_votes = sum(candidatevotes), .groups = \"drop\") |&gt;\n  rename(\"party\" = \"party_detailed\")\n\n# Congress and Presidential data merged and vote difference calculation\nvote_difference &lt;- congress_votes |&gt;\n  inner_join(president_votes, by = c(\"year\", \"state\", \"party\")) |&gt;\n  mutate(vote_difference = president_votes - congress_votes) |&gt;\n  select(-president_votes, -congress_votes)\n  \n# Democrat and Republican vote data\nselected_parties &lt;- vote_difference |&gt;\n  filter(party %in% c(\"DEMOCRAT\", \"REPUBLICAN\")) |&gt;\n  group_by(year, party) |&gt;\n  summarise(avg_vote_diff = mean(vote_difference))\n\n# Display the results in a datatable\ntabledata &lt;- vote_difference |&gt;\n  filter(party %in% c(\"DEMOCRAT\", \"REPUBLICAN\")) |&gt;\n  select(state, party,vote_difference)\n\ndatatable(setNames(tabledata, c(\"State\", \"Party\", \"Vote Difference\")),\n          options = list(pageLength = 10, autoWidth = TRUE),\n          caption = \"Table 3: Presidential Votes vs Congress Votes\") |&gt;\n  formatRound(columns = \"Vote Difference\", digits = 0)\n\n\n\n\n\n\n\n\nCode\n# Plot average vote difference by year and party\nggplot(selected_parties, aes(x = year, y = avg_vote_diff, color = party)) +\n  geom_line() +\n  scale_color_manual(values = c(\"DEMOCRAT\" = \"blue\", \"REPUBLICAN\" = \"red\")) +\n  labs(title = \"Graph 2: Vote Difference (Presidential - Congressional) by Party Over Time\",\n       x = \"Year\", y = \"Average Vote Difference\") +\n  theme_minimal() |&gt;\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\nThe table and graph above show the vote difference between presidential and congressional candidates across various states, broken down by party. Presidential candidates’ performance does not always align with their party’s performance in congressional races. In some cases, the presidential candidates outperform their congressional counterparts, while in others, it’s the reverse. The vote differences can vary significantly across states and parties, indicating that voter preferences for presidential and congressional candidates can be quite different."
  },
  {
    "objectID": "mp03.html#chloropleth-visualization-2000-presidential-elections",
    "href": "mp03.html#chloropleth-visualization-2000-presidential-elections",
    "title": "Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "",
    "text": "From the district file downloaded earlier, we will need to read and extract the shape files for further analysis of the 2000 presidential elections.\n\n\nCode\nzip_file &lt;- \"districts106.zip\"\n\n# Extract the contents of the zip files\nunzip(zip_file)\n\n# Read the 106th district shape file\nshapefile_106 &lt;- st_read(file.path(\"districtShapes/districts106.shp\"))\n\n\nReading layer `districts106' from data source \n  `C:\\Users\\Timbila Nikiema\\OneDrive\\Documents\\STA9750-2024-FALL\\districtShapes\\districts106.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 436 features and 15 fields (with 1 geometry empty)\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -179.1473 ymin: 18.9177 xmax: 179.7785 ymax: 71.35256\nGeodetic CRS:  GRS 1980(IUGG, 1980)\n\n\nThe following R code creates a choropleth map visualizing the 2000 U.S. presidential election results by state. Using election data joined with U.S. state geometries, the map displays each state colored by the winning party (Republican or Democratic). Insets for Alaska and Hawaii are added for clarity, and each state is labeled with its two-letter postal abbreviation for easier identification. This visualization provides a clear, geographic perspective of the electoral outcomes across the contiguous United States, with separate, scaled-down views of Alaska and Hawaii.\n\n\nCode\n# Task 5: Chloropleth Visualization of the 2000 Presidential Election Electoral College Results\n\n# 2000 elections data\nelections_2000 &lt;- PRESIDENT_DATA |&gt;\n  filter(year == 2000) |&gt;\n  group_by(state, party_simplified) |&gt;\n  summarize(total_votes = sum(candidatevotes), .groups = \"drop\") |&gt;\n  group_by(state) |&gt;\n  slice_max(total_votes, n = 1) |&gt;\n  ungroup() |&gt;\n  select(state, party_simplified) |&gt;\n  rename(Party = party_simplified)\n\n# join the shape file to election results\nshapefile_us_2000 &lt;- shapefile_106 |&gt;\n  mutate(STATENAME = toupper(trimws(STATENAME))) |&gt; \n  left_join(elections_2000, join_by(STATENAME == state))\n\n# create Choropleth of contiguous US first\nconsolidated_map &lt;- ggplot(shapefile_us_2000, aes(geometry = geometry, fill = Party), color = \"black\") +\n  geom_sf() +\n  scale_fill_manual(values = c(\"DEMOCRAT\" = \"skyblue3\", \"REPUBLICAN\" = \"firebrick1\")) +\n  theme_minimal() +\n  labs(title = \"Graph 3: 2000 Presidential Election Results by State\", fill = \"Party\") +\n  theme(legend.position = \"bottom\") +\n  coord_sf(xlim = c(-130, -60), ylim = c(20, 50), expand = FALSE)\n\n# Alaska inset\nalaska_sf &lt;- shapefile_us_2000[shapefile_us_2000$STATENAME == \"ALASKA\", ]\ninset_alaska &lt;- ggplot(alaska_sf,\n  aes(geometry = geometry, fill = Party), color = \"black\") +\n  geom_sf() +\n  scale_fill_manual(values = c(\"DEMOCRAT\" = \"skyblue3\", \"REPUBLICAN\" = \"firebrick1\")) +\n  theme_void() +\n  theme(legend.position = \"none\") +\n  coord_sf(xlim = c(-180, -140), ylim = c(50, 72), expand = FALSE)\n\n# Hawaii inset\nhawaii_sf &lt;- shapefile_us_2000[shapefile_us_2000$STATENAME == \"HAWAII\", ]\ninset_hawaii &lt;- ggplot(hawaii_sf, aes(geometry = geometry, fill = Party), color = \"black\") +\n  geom_sf() +\n  scale_fill_manual(values = c(\"DEMOCRAT\" = \"skyblue3\", \"REPUBLICAN\" = \"firebrick1\")) +\n  theme_void() +\n  theme(legend.position = \"none\") +\n  coord_sf(xlim = c(-161, -154), ylim = c(20, 22), expand = FALSE)\n\ncombined_map &lt;- consolidated_map +\n  annotation_custom(ggplotGrob(inset_alaska),\n    xmin = -120, xmax = -130, # Adjust position for Alaska\n    ymin = 15, ymax = 40) +\n  annotation_custom(ggplotGrob(inset_hawaii),\n    xmin = -115, xmax = -100, # Adjust position for Hawaii\n    ymin = 20, ymax = 30) # Adjust these values to fit\n\n# Print the combined map\nprint(combined_map)"
  },
  {
    "objectID": "mp03.html#chloropleth-visualization-presidential-elections-1976---2020",
    "href": "mp03.html#chloropleth-visualization-presidential-elections-1976---2020",
    "title": "Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "",
    "text": "Code\n# Task 6: Advanced Chloropleth Visualization of Electoral College Results\n\n# Modify your previous code to make an animated version showing election results over time.\n\n# List of election years\nelection_years &lt;- c(1976, 1980, 1984, 1988, 1992, 1996, 2000, 2004, 2008, 2012, 2016, 2020)\n\n# Function to process election results for a specific year\nwinner_by_year &lt;- function(input_year) {\n  PRESIDENT_DATA |&gt;\n    filter(year == input_year) |&gt; # Filter for the specific year\n    group_by(state, party_simplified) |&gt;\n    summarize(total_votes = sum(candidatevotes), .groups = \"drop\") |&gt;\n    group_by(state) |&gt;\n    slice_max(total_votes, n = 1) |&gt;\n    ungroup() |&gt;\n    select(state, party_simplified) |&gt;\n    rename(winning_party = party_simplified) |&gt;\n    mutate(year = input_year) # Add year to the table\n}\n\n# Combine each year's results into one data table\nelection_results &lt;- bind_rows(lapply(election_years, winner_by_year))\n\n# Load the state shape files\nstates_shapes &lt;- st_read(\"tl_2020_us_state.shp\") |&gt;\n  mutate(STATE = toupper(trimws(NAME)))\n\n\nReading layer `tl_2020_us_state' from data source \n  `C:\\Users\\Timbila Nikiema\\OneDrive\\Documents\\STA9750-2024-FALL\\tl_2020_us_state.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 56 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -179.2311 ymin: -14.60181 xmax: 179.8597 ymax: 71.43979\nGeodetic CRS:  NAD83\n\n\nCode\n# Exclude Alaska and Hawaii\nstates_shapes &lt;- states_shapes |&gt; \n  filter(!STATE %in% c(\"ALASKA\", \"HAWAII\"))\n\n# Join the election data with the shapefile for all years\nelection_results &lt;- states_shapes |&gt;\n  left_join(election_results |&gt; mutate(state = toupper(trimws(state))), \n            by = c(\"STATE\" = \"state\")) |&gt; \n  filter(!is.na(year)) # Excluding any NAs\n\n# Create the animated plot\nanimate_election_results &lt;- ggplot(election_results, aes(geometry = geometry, fill = winning_party), color = \"black\") +\n  geom_sf() +\n  scale_fill_manual(values = c(\"DEMOCRAT\" = \"skyblue3\", \"REPUBLICAN\" = \"firebrick1\")) +\n  theme_minimal() +\n  labs(title = \"Graph 4: Presidential Election State Results {closest_state}\", fill = \"Winning Party\") +\n  theme(legend.position = \"bottom\") +\n  transition_states(year, transition_length = 0, state_length = 1) +\n  coord_sf(xlim = c(-125, -65), ylim = c(25, 50), expand = FALSE) # Exclude Alaska and Hawaii\n\n# Print the animated graph\nanimate(animate_election_results, fps = 10)"
  },
  {
    "objectID": "mp03.html#comparing-the-effects-of-ecv-allocation-rules",
    "href": "mp03.html#comparing-the-effects-of-ecv-allocation-rules",
    "title": "Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "",
    "text": "To evaluate the fairness and effects of different Electoral College Vote (ECV) allocation schemes, we’ll walk through a series of steps for each allocation mentioned strategies. The analysis will include comparing each allocation scheme’s results against the historical winners to uncover any systematic biases, and then assessing which scheme is “fairest” in terms of how it impacts election outcomes.\n\n\nThe candidate with the most votes in the state wins all the state’s electoral votes.\n\n\nCode\n# Electoral college count\nelectoral_count &lt;- HOUSE_DATA |&gt;\n  group_by(year, state) |&gt;\n  summarise(reps_count = n_distinct(district)) |&gt;\n  mutate(electoral_votes = reps_count + 2) |&gt; \n  select(year, state, electoral_votes)\n\n# find the candidate with the most votes each year in each state\nstate_wide_winner_take_all &lt;- PRESIDENT_DATA |&gt;\n  group_by(year, state, candidate) |&gt;\n  summarize(total_votes = sum(candidatevotes), .groups = \"drop\") |&gt;\n  group_by(year, state) |&gt;\n  slice_max(order_by = total_votes, n = 1, with_ties = FALSE) |&gt; # find the winner of each state based on total votes\n  rename(winner = candidate) # rename for conventional understanding\n\n# join the state, winner, and number of electoral votes & sum which candidate that gets the most electoral votes\nstate_wide_winner_take_all &lt;- state_wide_winner_take_all |&gt;\n  left_join(electoral_count,\n    by = c(\"year\", \"state\")) |&gt;\n  group_by(year, winner) |&gt;\n  summarize(total_electoral_votes = sum(electoral_votes)) |&gt; # sum electoral votes across all states by candidate each year\n  slice_max(order_by = total_electoral_votes, n = 1, with_ties = FALSE)\n\n\n\n\nCode\ndatatable(setNames(state_wide_winner_take_all, c(\"Year\", \"Winning Candidate\", \"Electoral Votes\")),\n          options = list(pageLength = 12, autoWidth = TRUE),\n          caption = \"Table 4: State-Wide Winner-Take-All: Presidential Winning Candidate\")\n\n\n\n\n\n\nThe WTA method tends to exaggerate the margin of victory for the winning candidate, disproportionately amplifying the impact of swing states. It can produce outcomes that diverge significantly from the national popular vote. For example: * 2000 Election: George W. Bush won the presidency with 271 ECVs to Al Gore’s 266, despite losing the popular vote. * 2016 Election: Donald Trump won the presidency with 305 ECVs to Hillary Clinton’s 227, again losing the popular vote.\n\n\n\nStates like Maine and Nebraska use this system, where electors are assigned both based on the winners of each congressional district (district-level WTA) and a set of electors awarded to the winner of the statewide vote. This is a hybrid of district-level and state-wide allocation.\n\n\nCode\n# find number of districts each party won to represent electoral votes won in each state\ndistrict_winner &lt;- HOUSE_DATA |&gt;\n  group_by(year, state, district) |&gt;\n  slice_max(order_by = candidatevotes, n = 1, with_ties = FALSE) |&gt;\n  select(year, state, district, party) |&gt;\n  group_by(year, state, party) |&gt;\n  summarize(districts_won = n()) # number of electoral votes received by each party\n\n# find popular vote winner in the state\nat_large_winner &lt;- HOUSE_DATA |&gt;\n  group_by(year, state) |&gt;\n  slice_max(order_by = candidatevotes, n = 1, with_ties = FALSE) |&gt;\n  select(year, state, party) |&gt;\n  add_column(at_large_votes = 2) # designating the vote count\n\n# join tables together to find total electoral votes the presidential party receives in each state\ndistrict_wide_winner_take_all &lt;- district_winner |&gt;\n  left_join(at_large_winner, by = c(\"year\", \"state\", \"party\")) |&gt;\n  mutate(across(where(is.numeric), ~ ifelse(is.na(.), 0, .))) |&gt; \n  mutate(total_electoral_votes = districts_won + at_large_votes) |&gt;\n  select(-districts_won, -at_large_votes) |&gt;\n  rename(party_simplified = party) |&gt; # rename for easier joining convention\n  left_join(PRESIDENT_DATA, by = c(\"year\", \"state\", \"party_simplified\")) |&gt; # join to presidential candidate\n  select(year, state, total_electoral_votes, candidate) |&gt;\n  group_by(year, candidate) |&gt;\n  summarize(electoral_votes = sum(total_electoral_votes)) |&gt;\n  slice_max(order_by = electoral_votes, n = 1, with_ties = FALSE) |&gt;\n  drop_na() # get rid of the non-presidential election years\n\n\n\n\nCode\ndatatable(setNames(district_wide_winner_take_all, c(\"Year\", \"Winning Candidate\", \"Electoral Votes\")),\n          options = list(pageLength = 12, autoWidth = TRUE),\n          caption = \"Table 5: District-Wide Winner-Take-All: Presidential Winning Candidate\")\n\n\n\n\n\n\nThis scheme introduces more granularity but can still deviate significantly from the popular vote due to district-level gerrymandering. In elections like 2012, Barack Obama won both Maine’s districts and the state, earning all its ECVs. In 2020, Nebraska awarded some ECVs to Joe Biden while awarding most to Donald Trump.\n\n\n\nThe state’s electoral votes are distributed proportionally based on the percentage of the popular vote each candidate receives. For example, if a candidate wins 40% of the vote in a state with 10 ECVs, they get 4 ECVs.\n\n\nCode\n# find the percentage of the votes received in each state\nstate_wide_proportional &lt;- PRESIDENT_DATA |&gt;\n  select(year, state, candidate, candidatevotes, totalvotes) |&gt;\n  mutate(percentage_state_votes = (candidatevotes / totalvotes)) |&gt;\n  select(-candidatevotes, -totalvotes)\n\n# find the number of electoral votes received by each candidate\nstate_wide_proportional &lt;- state_wide_proportional |&gt;\n  inner_join(electoral_count, by = c(\"year\", \"state\")) |&gt;\n  mutate(votes_received = round(percentage_state_votes * electoral_votes, digits = 0)) |&gt;\n  select(-percentage_state_votes, -electoral_votes)\n\n# sum total votes and find presidential winner\nstate_wide_proportional &lt;- state_wide_proportional |&gt;\n  group_by(year, candidate) |&gt;\n  summarize(total_electoral_votes = sum(votes_received)) |&gt;\n  slice_max(order_by = total_electoral_votes, n = 1, with_ties = FALSE) |&gt;\n  rename(winner = candidate)\n\n\n\n\nCode\ndatatable(setNames(state_wide_proportional, c(\"Year\", \"Winning Candidate\", \"Electoral Votes\")),\n          options = list(pageLength = 12, autoWidth = TRUE),\n          caption = \"Table 6: State-Wide Proportional: Presidential Winning Candidate\")\n\n\n\n\n\n\nThis scheme aligns more closely with the popular vote, reducing distortions caused by WTA. However, it may lead to no candidate receiving a majority of ECVs, increasing the likelihood of the election being decided by the House of Representatives.\n\n\n\nElectoral votes are distributed proportionally across the entire nation rather than by state, based on the percentage of the national popular vote each candidate receives. This system eliminates the state-based winner-take-all feature and distributes ECVs based purely on national vote share.\n\n\nCode\n# find total number of electoral votes available\nelectoral_votes_available &lt;- electoral_count |&gt;\n  group_by(year) |&gt;\n  summarize(electoral_college_votes = sum(electoral_votes))\n\n# find percentage of popular vote each candidate received\nnational_proportional &lt;- PRESIDENT_DATA |&gt;\n  select(year, state, candidate, candidatevotes) |&gt;\n  group_by(year, candidate) |&gt;\n  summarize(total_electoral_votes = sum(candidatevotes)) |&gt;\n  group_by(year) |&gt;\n  mutate(population_vote_count = sum(total_electoral_votes)) |&gt; # find total number of votes cast in election year\n  ungroup() |&gt;\n  mutate(percentage_population_vote = (total_electoral_votes / population_vote_count)) |&gt;\n  select(-total_electoral_votes, -population_vote_count) |&gt;\n  \n  # find the allocation of the electoral votes based on the popular vote percentage\n  left_join(electoral_votes_available, join_by(year == year)) |&gt;\n  mutate(electoral_votes_received = round(percentage_population_vote * electoral_college_votes, digits = 0)) |&gt;\n  select(-percentage_population_vote, -electoral_college_votes) |&gt;\n  group_by(year) |&gt;\n  slice_max(order_by = electoral_votes_received, n = 1, with_ties = FALSE) |&gt;\n  rename(winner = candidate)\n\n\n\n\nCode\ndatatable(setNames(national_proportional, c(\"Year\", \"Winning Candidate\", \"Electoral Votes\")),\n          options = list(pageLength = 12, autoWidth = TRUE),\n          caption = \"Table 7: National Proportional: Presidential Winning Candidate\")\n\n\n\n\n\n\n\n\nCode\n# Load the necessary package\nlibrary(knitr)\nlibrary(kableExtra)\n\n# Create the data frame\ncomparison_table &lt;- data.frame(\n  \"Allocation Method\" = c(\n    \"State-Wide Winner-Take-All\", \n    \"District-Based Allocation\", \n    \"Proportional Allocation\"\n  ),\n  \"Popular Vote Alignment\" = c(\"Low\", \"Moderate\", \"High\"),\n  \"Swing State Influence\" = c(\"High\", \"Moderate\", \"Low\"),\n  \"Fairness\" = c(\"Biased\", \"Mixed\", \"Fairest\"),\n  \"Example Outcome\" = c(\n    \"2000: Bush wins despite losing PV\",\n    \"Amplifies gerrymandering effects\",\n    \"2000: Gore wins, aligning with PV\"))\n\n# Generate and format the table with adjustable size\ncomparison_table |&gt; \n  kable(\n    caption = \"Comparison of Allocation Methods:\",\n    col.names = c(\"Allocation Method\", \"Popular Vote Alignment\", \"Swing State Influence\", \"Fairness\", \"Example Outcome\"), align = \"l\") |&gt; \n  kable_styling(\n    full_width = TRUE,     # Make the table use the full width\n    position = \"center\",   # Center-align the table\n    font_size = 14)        # Adjust the font size for better readability\n\n\n\nComparison of Allocation Methods:\n\n\nAllocation Method\nPopular Vote Alignment\nSwing State Influence\nFairness\nExample Outcome\n\n\n\n\nState-Wide Winner-Take-All\nLow\nHigh\nBiased\n2000: Bush wins despite losing PV\n\n\nDistrict-Based Allocation\nModerate\nModerate\nMixed\nAmplifies gerrymandering effects\n\n\nProportional Allocation\nHigh\nLow\nFairest\n2000: Gore wins, aligning with PV"
  },
  {
    "objectID": "mp03.html#conclusion",
    "href": "mp03.html#conclusion",
    "title": "Mini-Project #03: Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "",
    "text": "Among the three methods, Proportional Allocation is the fairest in terms of aligning with the popular vote and reducing distortions caused by state size or swing state dynamics. However, its drawback of potentially not producing a decisive winner suggests that reforms should carefully weigh the trade-offs between fairness and administrative simplicity.\nThe Winner-Take-All method is the least fair due to its high distortions, as seen in elections like 2000 and 2016. Meanwhile, District-Based Allocation offers granularity but suffers from gerrymandering issues. Proportional allocation represents the best balance for fairness and voter representation."
  }
]